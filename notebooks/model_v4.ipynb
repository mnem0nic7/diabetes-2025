{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bb90ea6",
   "metadata": {},
   "source": [
    "# Model V4: Back to Basics - Focus on Generalization\n",
    "\n",
    "**Problem:** CV scores improved but LB scores got worse = overfitting\n",
    "\n",
    "**Strategy:**\n",
    "1. Minimal feature engineering (only domain-relevant features)\n",
    "2. Strong regularization\n",
    "3. Simpler models with fewer hyperparameters\n",
    "4. Proper CV-based target encoding (with fold-out)\n",
    "5. Remove target encoding entirely (it often leaks)\n",
    "6. Use original data + only most robust features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a807fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9f3fd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (700000, 26), Test: (300000, 25)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "print(f\"Train: {train.shape}, Test: {test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ef0150",
   "metadata": {},
   "source": [
    "## Minimal Feature Engineering\n",
    "Only add features that are clearly domain-relevant and unlikely to overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb18941c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (700000, 30), Test: (300000, 29)\n",
      "Added features: 4\n"
     ]
    }
   ],
   "source": [
    "def minimal_feature_engineering(df):\n",
    "    \"\"\"Only add robust, domain-relevant features\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Simple cholesterol ratios (medically meaningful)\n",
    "    df['ldl_hdl_ratio'] = df['ldl_cholesterol'] / (df['hdl_cholesterol'] + 1)\n",
    "    \n",
    "    # Combined risk factors (simple counts, not complex scores)\n",
    "    df['risk_factor_count'] = (df['family_history_diabetes'] + \n",
    "                                df['hypertension_history'] + \n",
    "                                df['cardiovascular_history'])\n",
    "    \n",
    "    # Blood pressure derived\n",
    "    df['pulse_pressure'] = df['systolic_bp'] - df['diastolic_bp']\n",
    "    \n",
    "    # Simple BMI-age interaction (well-known diabetes risk factor)\n",
    "    df['age_bmi'] = df['age'] * df['bmi']\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_fe = minimal_feature_engineering(train)\n",
    "test_fe = minimal_feature_engineering(test)\n",
    "print(f\"Train: {train_fe.shape}, Test: {test_fe.shape}\")\n",
    "print(f\"Added features: {train_fe.shape[1] - train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7fa85b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 28\n",
      "Feature list: ['age', 'alcohol_consumption_per_week', 'physical_activity_minutes_per_week', 'diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day', 'bmi', 'waist_to_hip_ratio', 'systolic_bp', 'diastolic_bp', 'heart_rate', 'cholesterol_total', 'hdl_cholesterol', 'ldl_cholesterol', 'triglycerides', 'gender', 'ethnicity', 'education_level', 'income_level', 'smoking_status', 'employment_status', 'family_history_diabetes', 'hypertension_history', 'cardiovascular_history', 'ldl_hdl_ratio', 'risk_factor_count', 'pulse_pressure', 'age_bmi']\n"
     ]
    }
   ],
   "source": [
    "# Prepare features - NO target encoding (common source of leakage)\n",
    "target = 'diagnosed_diabetes'\n",
    "cat_cols = ['gender', 'ethnicity', 'education_level', 'income_level', 'smoking_status', 'employment_status']\n",
    "\n",
    "X = train_fe.drop(columns=['id', target])\n",
    "y = train_fe[target]\n",
    "X_test = test_fe.drop(columns=['id'])\n",
    "\n",
    "# Simple label encoding for categoricals\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    all_vals = pd.concat([X[col], X_test[col]]).unique()\n",
    "    le.fit(all_vals)\n",
    "    X[col] = le.transform(X[col])\n",
    "    X_test[col] = le.transform(X_test[col])\n",
    "\n",
    "print(f\"Features: {X.shape[1]}\")\n",
    "print(f\"Feature list: {list(X.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b95b1a",
   "metadata": {},
   "source": [
    "## Conservative Model Parameters\n",
    "Use stronger regularization to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d6fd2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conservative parameters configured\n"
     ]
    }
   ],
   "source": [
    "# Conservative parameters - prioritize generalization over CV score\n",
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.03,  # Lower learning rate\n",
    "    'n_estimators': 500,\n",
    "    'max_depth': 5,  # Shallower trees\n",
    "    'num_leaves': 20,  # Fewer leaves\n",
    "    'min_child_samples': 100,  # More samples per leaf\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'reg_alpha': 1.0,  # Strong L1 regularization\n",
    "    'reg_lambda': 1.0,  # Strong L2 regularization\n",
    "    'random_state': 42,\n",
    "    'verbosity': -1,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'learning_rate': 0.03,\n",
    "    'n_estimators': 500,\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 100,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'reg_alpha': 1.0,\n",
    "    'reg_lambda': 1.0,\n",
    "    'random_state': 42,\n",
    "    'verbosity': 0,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "cat_params = {\n",
    "    'iterations': 500,\n",
    "    'learning_rate': 0.03,\n",
    "    'depth': 5,\n",
    "    'l2_leaf_reg': 10,  # Strong regularization\n",
    "    'min_data_in_leaf': 100,\n",
    "    'random_seed': 42,\n",
    "    'verbose': False,\n",
    "    'eval_metric': 'AUC'\n",
    "}\n",
    "\n",
    "print(\"Conservative parameters configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7550df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with conservative parameters...\n",
      "\n",
      "Fold 1\n",
      "  LGB: 0.72092, XGB: 0.72113, CAT: 0.71380\n",
      "Fold 2\n",
      "  LGB: 0.71913, XGB: 0.71891, CAT: 0.71206\n",
      "Fold 3\n",
      "  LGB: 0.72010, XGB: 0.72002, CAT: 0.71227\n",
      "Fold 4\n",
      "  LGB: 0.72075, XGB: 0.72114, CAT: 0.71355\n",
      "Fold 5\n",
      "  LGB: 0.72041, XGB: 0.72089, CAT: 0.71359\n",
      "\n",
      "==================================================\n",
      "LightGBM CV AUC: 0.72026\n",
      "XGBoost CV AUC:  0.72041\n",
      "CatBoost CV AUC: 0.71304\n"
     ]
    }
   ],
   "source": [
    "# Train with 5-fold CV\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "oof_lgb = np.zeros(len(X))\n",
    "oof_xgb = np.zeros(len(X))\n",
    "oof_cat = np.zeros(len(X))\n",
    "\n",
    "test_lgb = np.zeros(len(X_test))\n",
    "test_xgb = np.zeros(len(X_test))\n",
    "test_cat = np.zeros(len(X_test))\n",
    "\n",
    "print(\"Training with conservative parameters...\\n\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # LightGBM\n",
    "    lgb_model = lgb.LGBMClassifier(**lgb_params)\n",
    "    lgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)],\n",
    "                  callbacks=[lgb.early_stopping(50, verbose=False)])\n",
    "    oof_lgb[val_idx] = lgb_model.predict_proba(X_val)[:, 1]\n",
    "    test_lgb += lgb_model.predict_proba(X_test)[:, 1] / n_splits\n",
    "    \n",
    "    # XGBoost\n",
    "    xgb_model = xgb.XGBClassifier(**xgb_params)\n",
    "    xgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "    oof_xgb[val_idx] = xgb_model.predict_proba(X_val)[:, 1]\n",
    "    test_xgb += xgb_model.predict_proba(X_test)[:, 1] / n_splits\n",
    "    \n",
    "    # CatBoost\n",
    "    cat_model = CatBoostClassifier(**cat_params)\n",
    "    cat_model.fit(X_train, y_train, eval_set=(X_val, y_val), \n",
    "                  early_stopping_rounds=50, verbose=False)\n",
    "    oof_cat[val_idx] = cat_model.predict_proba(X_val)[:, 1]\n",
    "    test_cat += cat_model.predict_proba(X_test)[:, 1] / n_splits\n",
    "    \n",
    "    print(f\"  LGB: {roc_auc_score(y_val, oof_lgb[val_idx]):.5f}, \"\n",
    "          f\"XGB: {roc_auc_score(y_val, oof_xgb[val_idx]):.5f}, \"\n",
    "          f\"CAT: {roc_auc_score(y_val, oof_cat[val_idx]):.5f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"LightGBM CV AUC: {roc_auc_score(y, oof_lgb):.5f}\")\n",
    "print(f\"XGBoost CV AUC:  {roc_auc_score(y, oof_xgb):.5f}\")\n",
    "print(f\"CatBoost CV AUC: {roc_auc_score(y, oof_cat):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd03cc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Average Ensemble CV AUC: 0.71862\n",
      "\n",
      "Submission saved: submission_v4.csv\n",
      "Prediction stats:\n",
      "count    300000.000000\n",
      "mean          0.603035\n",
      "std           0.180007\n",
      "min           0.065644\n",
      "25%           0.476365\n",
      "50%           0.604267\n",
      "75%           0.733117\n",
      "max           0.985545\n",
      "Name: diagnosed_diabetes, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Simple averaging ensemble (equal weights - less prone to overfitting)\n",
    "oof_ensemble = (oof_lgb + oof_xgb + oof_cat) / 3\n",
    "test_ensemble = (test_lgb + test_xgb + test_cat) / 3\n",
    "\n",
    "print(f\"Simple Average Ensemble CV AUC: {roc_auc_score(y, oof_ensemble):.5f}\")\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'diagnosed_diabetes': test_ensemble\n",
    "})\n",
    "submission.to_csv('submission_v4.csv', index=False)\n",
    "print(f\"\\nSubmission saved: submission_v4.csv\")\n",
    "print(f\"Prediction stats:\\n{submission['diagnosed_diabetes'].describe()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9186d3",
   "metadata": {},
   "source": [
    "## Also try: Pure raw features (no engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7333332f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw features: 24\n",
      "Raw LightGBM CV AUC: 0.72070\n",
      "Saved submission_v4_raw.csv\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Try with ZERO feature engineering - just raw data\n",
    "X_raw = train.drop(columns=['id', target])\n",
    "X_test_raw = test.drop(columns=['id'])\n",
    "\n",
    "# Label encode categoricals\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    all_vals = pd.concat([X_raw[col], X_test_raw[col]]).unique()\n",
    "    le.fit(all_vals)\n",
    "    X_raw[col] = le.transform(X_raw[col])\n",
    "    X_test_raw[col] = le.transform(X_test_raw[col])\n",
    "\n",
    "print(f\"Raw features: {X_raw.shape[1]}\")\n",
    "\n",
    "# Train just LightGBM (fastest) with raw features\n",
    "oof_raw = np.zeros(len(X_raw))\n",
    "test_raw = np.zeros(len(X_test_raw))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_raw, y)):\n",
    "    X_train, X_val = X_raw.iloc[train_idx], X_raw.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    lgb_model = lgb.LGBMClassifier(**lgb_params)\n",
    "    lgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)],\n",
    "                  callbacks=[lgb.early_stopping(50, verbose=False)])\n",
    "    oof_raw[val_idx] = lgb_model.predict_proba(X_val)[:, 1]\n",
    "    test_raw += lgb_model.predict_proba(X_test_raw)[:, 1] / n_splits\n",
    "\n",
    "print(f\"Raw LightGBM CV AUC: {roc_auc_score(y, oof_raw):.5f}\")\n",
    "\n",
    "# Save raw submission\n",
    "submission_raw = pd.DataFrame({'id': test['id'], 'diagnosed_diabetes': test_raw})\n",
    "submission_raw.to_csv('submission_v4_raw.csv', index=False)\n",
    "print(\"Saved submission_v4_raw.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
