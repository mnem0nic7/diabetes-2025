{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a2a4ce89",
      "metadata": {},
      "source": [
        "# V8 — shift-first pipeline (clean rebuild)\n",
        "\n",
        "This notebook reimplements V8 end-to-end on disk (no corrupted cells).\n",
        "\n",
        "Steps:\n",
        "1. Domain classifier → p_test(train), p_test(test)\n",
        "2. Shift-aware CV metrics\n",
        "3. Mixture: full vs top-50% test-like subset + blend\n",
        "4. Importance-weighted training\n",
        "5. Soft de-emphasis: quantile binning (integer codes)\n",
        "6. Gated blend on test (row-wise)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "561bf058",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import StratifiedKFold, StratifiedGroupKFold, KFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "SEED = 42\n",
        "N_SPLITS = 10\n",
        "TARGET = 'diagnosed_diabetes'\n",
        "DATA_DIR = 'data'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "36933b49",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (700000, 26)\n",
            "Test shape : (300000, 25)\n",
            "Target rate: 0.6232957142857143\n",
            "Categorical cols: ['gender', 'ethnicity', 'education_level', 'income_level', 'smoking_status', 'employment_status']\n"
          ]
        }
      ],
      "source": [
        "train = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
        "test = pd.read_csv(os.path.join(DATA_DIR, 'test.csv'))\n",
        "\n",
        "print('Train shape:', train.shape)\n",
        "print('Test shape :', test.shape)\n",
        "print('Target rate:', train[TARGET].mean())\n",
        "\n",
        "test_ids = test['id']\n",
        "train = train.drop(columns=['id'])\n",
        "test = test.drop(columns=['id'])\n",
        "\n",
        "def to_category(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    out = df.copy()\n",
        "    for c in out.columns:\n",
        "        if out[c].dtype == 'object':\n",
        "            out[c] = out[c].astype('category')\n",
        "    return out\n",
        "\n",
        "train = to_category(train)\n",
        "test = to_category(test)\n",
        "\n",
        "y = train[TARGET].astype(int)\n",
        "X = train.drop(columns=[TARGET])\n",
        "X_test = test.copy()\n",
        "\n",
        "cat_cols = X.select_dtypes(include=['category']).columns.tolist()\n",
        "print('Categorical cols:', cat_cols)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f10f0c68",
      "metadata": {},
      "source": [
        "## 1) Domain classifier → test-likeness score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c29f0faa",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Domain (train vs test) CV AUC: 0.64956\n",
            "p_test(train) quantiles: [0.08491359 0.19052777 0.24689076 0.37697885 0.95289083]\n",
            "p_test(test)  quantiles: [0.1139838  0.22369724 0.32782366 0.59714959 0.98700743]\n"
          ]
        }
      ],
      "source": [
        "def fit_domain_classifier_get_p_test(X_train: pd.DataFrame, X_test: pd.DataFrame, seed: int = 42):\n",
        "    X_all = pd.concat([X_train, X_test], axis=0, ignore_index=True)\n",
        "    y_dom = np.concatenate([np.zeros(len(X_train), dtype=int), np.ones(len(X_test), dtype=int)])\n",
        "\n",
        "    params = {\n",
        "        'objective': 'binary',\n",
        "        'metric': 'auc',\n",
        "        'boosting_type': 'gbdt',\n",
        "        'n_estimators': 4000,\n",
        "        'learning_rate': 0.02,\n",
        "        'num_leaves': 63,\n",
        "        'max_depth': -1,\n",
        "        'min_child_samples': 100,\n",
        "        'feature_fraction': 0.8,\n",
        "        'bagging_fraction': 0.8,\n",
        "        'bagging_freq': 1,\n",
        "        'reg_alpha': 0.0,\n",
        "        'reg_lambda': 1.0,\n",
        "        'random_state': seed,\n",
        "        'verbose': -1,\n",
        "    }\n",
        "\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "    oof = np.zeros(len(X_all))\n",
        "    for tr, va in kf.split(X_all, y_dom):\n",
        "        m = lgb.LGBMClassifier(**params)\n",
        "        m.fit(\n",
        "            X_all.iloc[tr], y_dom[tr],\n",
        "            eval_set=[(X_all.iloc[va], y_dom[va])],\n",
        "            callbacks=[lgb.early_stopping(100, verbose=False)]\n",
        "        )\n",
        "        oof[va] = m.predict_proba(X_all.iloc[va])[:, 1]\n",
        "\n",
        "    dom_auc = roc_auc_score(y_dom, oof)\n",
        "    print(f'Domain (train vs test) CV AUC: {dom_auc:.5f}')\n",
        "\n",
        "    final = lgb.LGBMClassifier(**params)\n",
        "    final.fit(X_all, y_dom)\n",
        "    p_all = final.predict_proba(X_all)[:, 1]\n",
        "    p_train = p_all[: len(X_train)]\n",
        "    p_test = p_all[len(X_train):]\n",
        "    return p_train, p_test, dom_auc\n",
        "\n",
        "p_test_train, p_test_test, dom_auc = fit_domain_classifier_get_p_test(X, X_test, seed=SEED)\n",
        "print('p_test(train) quantiles:', np.quantile(p_test_train, [0, 0.1, 0.5, 0.9, 1]))\n",
        "print('p_test(test)  quantiles:', np.quantile(p_test_test, [0, 0.1, 0.5, 0.9, 1]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bffb039",
      "metadata": {},
      "source": [
        "## 2) Shift-aware CV metrics + baseline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9c969b72",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "weights quantiles: [ 0.50547551  0.594876    0.82854668  1.52927051 12.63688783]\n",
            "[V8_BASE_SHIFT_CV] CV AUC std: 0.72897 | weighted: 0.73988 | val-top30%: 0.74692\n",
            "Saved: submission_v8_base_shiftcv.csv\n"
          ]
        }
      ],
      "source": [
        "def density_ratio_weights(p: np.ndarray, clip=(0.2, 5.0)):\n",
        "    eps = 1e-6\n",
        "    p = np.clip(p, eps, 1 - eps)\n",
        "    w = p / (1 - p)\n",
        "    w = np.clip(w, clip[0], clip[1])\n",
        "    w = w / np.mean(w)\n",
        "    return w\n",
        "\n",
        "w_train = density_ratio_weights(p_test_train, clip=(0.2, 5.0))\n",
        "print('weights quantiles:', np.quantile(w_train, [0, 0.1, 0.5, 0.9, 1]))\n",
        "\n",
        "def make_shift_groups(p_test: np.ndarray, n_bins: int = 50):\n",
        "    qs = np.quantile(p_test, np.linspace(0, 1, n_bins + 1))\n",
        "    qs = np.unique(qs)\n",
        "    if len(qs) <= 2:\n",
        "        return np.zeros_like(p_test, dtype=int)\n",
        "    return np.digitize(p_test, qs[1:-1], right=True)\n",
        "\n",
        "def cv_lgb_shift_metrics(\n",
        "    X: pd.DataFrame,\n",
        "    y: pd.Series,\n",
        "    X_test: pd.DataFrame,\n",
        "    p_test_train: np.ndarray,\n",
        "    sample_weight: np.ndarray | None = None,\n",
        "    seed: int = 42,\n",
        "    n_splits: int = 10,\n",
        "    use_shift_groups: bool = True,\n",
        "    label: str = 'model',\n",
        "):\n",
        "    params = {\n",
        "        'objective': 'binary',\n",
        "        'metric': 'auc',\n",
        "        'boosting_type': 'gbdt',\n",
        "        'n_estimators': 8000,\n",
        "        'learning_rate': 0.01,\n",
        "        'num_leaves': 31,\n",
        "        'max_depth': 6,\n",
        "        'min_child_samples': 80,\n",
        "        'feature_fraction': 0.7,\n",
        "        'bagging_fraction': 0.7,\n",
        "        'bagging_freq': 5,\n",
        "        'reg_alpha': 0.5,\n",
        "        'reg_lambda': 0.5,\n",
        "        'random_state': seed,\n",
        "        'verbose': -1,\n",
        "    }\n",
        "\n",
        "    if use_shift_groups:\n",
        "        groups = make_shift_groups(p_test_train, n_bins=50)\n",
        "        splitter = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "        splits = splitter.split(X, y, groups=groups)\n",
        "    else:\n",
        "        splitter = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "        splits = splitter.split(X, y)\n",
        "\n",
        "    oof = np.zeros(len(X))\n",
        "    test_pred = np.zeros(len(X_test))\n",
        "    fold_top = []\n",
        "\n",
        "    w_proxy = density_ratio_weights(p_test_train, clip=(0.2, 5.0))\n",
        "\n",
        "    for tr, va in splits:\n",
        "        X_tr, X_va = X.iloc[tr], X.iloc[va]\n",
        "        y_tr, y_va = y.iloc[tr], y.iloc[va]\n",
        "        fit_w = sample_weight[tr] if sample_weight is not None else None\n",
        "\n",
        "        m = lgb.LGBMClassifier(**params)\n",
        "        m.fit(\n",
        "            X_tr, y_tr,\n",
        "            sample_weight=fit_w,\n",
        "            eval_set=[(X_va, y_va)],\n",
        "            callbacks=[lgb.early_stopping(200, verbose=False)]\n",
        "        )\n",
        "        p_va = m.predict_proba(X_va)[:, 1]\n",
        "        oof[va] = p_va\n",
        "        test_pred += m.predict_proba(X_test)[:, 1] / n_splits\n",
        "\n",
        "        thr = np.quantile(p_test_train[va], 0.70)\n",
        "        idx_top = va[p_test_train[va] >= thr]\n",
        "        if len(idx_top) > 50:\n",
        "            fold_top.append(roc_auc_score(y.iloc[idx_top], oof[idx_top]))\n",
        "        else:\n",
        "            fold_top.append(np.nan)\n",
        "\n",
        "    overall_std = roc_auc_score(y, oof)\n",
        "    overall_w = roc_auc_score(y, oof, sample_weight=w_proxy)\n",
        "    overall_top = np.nanmean(fold_top)\n",
        "\n",
        "    print(f'[{label}] CV AUC std: {overall_std:.5f} | weighted: {overall_w:.5f} | val-top30%: {overall_top:.5f}')\n",
        "    return oof, test_pred\n",
        "\n",
        "oof_v8_base, pred_v8_base = cv_lgb_shift_metrics(\n",
        "    X, y, X_test, p_test_train,\n",
        "    sample_weight=None, seed=SEED, n_splits=N_SPLITS, use_shift_groups=True,\n",
        "    label='V8_BASE_SHIFT_CV'\n",
        ")\n",
        "pd.DataFrame({'id': test_ids, TARGET: pred_v8_base}).to_csv('submission_v8_base_shiftcv.csv', index=False)\n",
        "print('Saved: submission_v8_base_shiftcv.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f82f147a",
      "metadata": {},
      "source": [
        "## 3) Mixture: top-50% test-like subset + blend\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9999eeb8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[V8_SUBSET_TOP50] subset_quantile=0.5 -> train rows used ~0.500\n",
            "[V8_SUBSET_TOP50] CV AUC std: 0.72665 | weighted: 0.73815\n",
            "Saved: submission_v8_subset_top50.csv\n",
            "Saved: submission_v8_mixture_60_40.csv\n"
          ]
        }
      ],
      "source": [
        "def cv_lgb_subset_model(\n",
        "    X: pd.DataFrame,\n",
        "    y: pd.Series,\n",
        "    X_test: pd.DataFrame,\n",
        "    p_test_train: np.ndarray,\n",
        "    subset_quantile: float = 0.5,\n",
        "    seed: int = 42,\n",
        "    n_splits: int = 10,\n",
        "    label: str = 'subset',\n",
        "):\n",
        "    params = {\n",
        "        'objective': 'binary',\n",
        "        'metric': 'auc',\n",
        "        'boosting_type': 'gbdt',\n",
        "        'n_estimators': 12000,\n",
        "        'learning_rate': 0.008,\n",
        "        'num_leaves': 31,\n",
        "        'max_depth': 6,\n",
        "        'min_child_samples': 120,\n",
        "        'feature_fraction': 0.7,\n",
        "        'bagging_fraction': 0.7,\n",
        "        'bagging_freq': 5,\n",
        "        'reg_alpha': 0.8,\n",
        "        'reg_lambda': 1.0,\n",
        "        'random_state': seed,\n",
        "        'verbose': -1,\n",
        "    }\n",
        "\n",
        "    groups = make_shift_groups(p_test_train, n_bins=50)\n",
        "    splitter = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "    splits = splitter.split(X, y, groups=groups)\n",
        "\n",
        "    oof = np.zeros(len(X))\n",
        "    test_pred = np.zeros(len(X_test))\n",
        "\n",
        "    q_thr = np.quantile(p_test_train, subset_quantile)\n",
        "    subset_mask = p_test_train >= q_thr\n",
        "    print(f'[{label}] subset_quantile={subset_quantile} -> train rows used ~{subset_mask.mean():.3f}')\n",
        "\n",
        "    for tr, va in splits:\n",
        "        tr_sub = tr[subset_mask[tr]]\n",
        "        if len(tr_sub) < 1000:\n",
        "            tr_sub = tr\n",
        "\n",
        "        m = lgb.LGBMClassifier(**params)\n",
        "        m.fit(\n",
        "            X.iloc[tr_sub], y.iloc[tr_sub],\n",
        "            eval_set=[(X.iloc[va], y.iloc[va])],\n",
        "            callbacks=[lgb.early_stopping(250, verbose=False)]\n",
        "        )\n",
        "        oof[va] = m.predict_proba(X.iloc[va])[:, 1]\n",
        "        test_pred += m.predict_proba(X_test)[:, 1] / n_splits\n",
        "\n",
        "    std_auc = roc_auc_score(y, oof)\n",
        "    w_auc = roc_auc_score(y, oof, sample_weight=density_ratio_weights(p_test_train, clip=(0.2, 5.0)))\n",
        "    print(f'[{label}] CV AUC std: {std_auc:.5f} | weighted: {w_auc:.5f}')\n",
        "    return oof, test_pred\n",
        "\n",
        "oof_v8_sub50, pred_v8_sub50 = cv_lgb_subset_model(\n",
        "    X, y, X_test, p_test_train, subset_quantile=0.50, seed=SEED, n_splits=N_SPLITS, label='V8_SUBSET_TOP50'\n",
        ")\n",
        "pd.DataFrame({'id': test_ids, TARGET: pred_v8_sub50}).to_csv('submission_v8_subset_top50.csv', index=False)\n",
        "print('Saved: submission_v8_subset_top50.csv')\n",
        "\n",
        "pred_v8_mixture_60_40 = 0.6 * pred_v8_base + 0.4 * pred_v8_sub50\n",
        "pd.DataFrame({'id': test_ids, TARGET: pred_v8_mixture_60_40}).to_csv('submission_v8_mixture_60_40.csv', index=False)\n",
        "print('Saved: submission_v8_mixture_60_40.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9d6811b",
      "metadata": {},
      "source": [
        "## 4) Importance-weighted + blend\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f621250c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[V8_IMPORTANCE_WEIGHTED] CV AUC std: 0.72811 | weighted: 0.73929 | val-top30%: 0.74641\n",
            "Saved: submission_v8_importance_weighted.csv\n",
            "Saved: submission_v8_blend_base_weighted_60_40.csv\n"
          ]
        }
      ],
      "source": [
        "oof_v8_w, pred_v8_w = cv_lgb_shift_metrics(\n",
        "    X, y, X_test, p_test_train,\n",
        "    sample_weight=w_train, seed=SEED, n_splits=N_SPLITS, use_shift_groups=True,\n",
        "    label='V8_IMPORTANCE_WEIGHTED'\n",
        ")\n",
        "pd.DataFrame({'id': test_ids, TARGET: pred_v8_w}).to_csv('submission_v8_importance_weighted.csv', index=False)\n",
        "print('Saved: submission_v8_importance_weighted.csv')\n",
        "\n",
        "blend_bw = 0.6 * pred_v8_base + 0.4 * pred_v8_w\n",
        "pd.DataFrame({'id': test_ids, TARGET: blend_bw}).to_csv('submission_v8_blend_base_weighted_60_40.csv', index=False)\n",
        "print('Saved: submission_v8_blend_base_weighted_60_40.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cdbdf61",
      "metadata": {},
      "source": [
        "## 5) Soft de-emphasis via quantile binning (integer bin codes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a60f52ff",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Soft-binned shapes: (700000, 24) (300000, 24)\n",
            "[V8_SOFT_BIN] CV AUC std: 0.69189 | weighted: 0.70316 | val-top30%: 0.70965\n",
            "Saved: submission_v8_soft_bin.csv\n",
            "Saved: submission_v8_blend_base_softbin_60_40.csv\n"
          ]
        }
      ],
      "source": [
        "def quantile_bin_joint(\n",
        "    X_train: pd.DataFrame,\n",
        "    X_test: pd.DataFrame,\n",
        "    cols: list[str],\n",
        "    n_bins: int = 50,\n",
        "    drop_original: bool = True,\n",
        "    suffix: str = '__qbin',\n",
        ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    Xt = X_train.copy()\n",
        "    Xs = X_test.copy()\n",
        "\n",
        "    for c in cols:\n",
        "        if c not in Xt.columns or c not in Xs.columns:\n",
        "            continue\n",
        "        if not pd.api.types.is_numeric_dtype(Xt[c]):\n",
        "            continue\n",
        "\n",
        "        s_all = pd.concat([Xt[c], Xs[c]], axis=0, ignore_index=True)\n",
        "        try:\n",
        "            b_all = pd.qcut(s_all, q=n_bins, duplicates='drop')\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "        codes = b_all.cat.codes.astype('int16')\n",
        "        Xt[c + suffix] = codes.iloc[: len(Xt)].reset_index(drop=True)\n",
        "        Xs[c + suffix] = codes.iloc[len(Xt):].reset_index(drop=True)\n",
        "\n",
        "        if drop_original:\n",
        "            Xt = Xt.drop(columns=[c])\n",
        "            Xs = Xs.drop(columns=[c])\n",
        "\n",
        "    return Xt, Xs\n",
        "\n",
        "shift_candidates = [\n",
        "    'triglycerides', 'cholesterol_total', 'cholesterol_hdl', 'cholesterol_ldl',\n",
        "    'glucose', 'hba1c', 'insulin', 'bmi',\n",
        "    'waist_circumference', 'hip_circumference', 'waist_hip_ratio',\n",
        "    'systolic_bp', 'diastolic_bp',\n",
        "    'age', 'income', 'education_years',\n",
        "    'physical_activity', 'sleep_hours',\n",
        "    'smoking_pack_years', 'alcohol_units',\n",
        "    'family_history_diabetes', 'diet_score', 'stress_level',\n",
        "    'heart_rate', 'creatinine', 'egfr', 'alt', 'ast', 'crp',\n",
        "]\n",
        "\n",
        "X_soft, X_test_soft = quantile_bin_joint(X, X_test, shift_candidates, n_bins=50, drop_original=True)\n",
        "print('Soft-binned shapes:', X_soft.shape, X_test_soft.shape)\n",
        "\n",
        "oof_v8_soft, pred_v8_soft = cv_lgb_shift_metrics(\n",
        "    X_soft, y, X_test_soft, p_test_train,\n",
        "    sample_weight=None, seed=SEED, n_splits=N_SPLITS, use_shift_groups=True,\n",
        "    label='V8_SOFT_BIN'\n",
        ")\n",
        "pd.DataFrame({'id': test_ids, TARGET: pred_v8_soft}).to_csv('submission_v8_soft_bin.csv', index=False)\n",
        "print('Saved: submission_v8_soft_bin.csv')\n",
        "\n",
        "pred_v8_blend_base_soft = 0.6 * pred_v8_base + 0.4 * pred_v8_soft\n",
        "pd.DataFrame({'id': test_ids, TARGET: pred_v8_blend_base_soft}).to_csv('submission_v8_blend_base_softbin_60_40.csv', index=False)\n",
        "print('Saved: submission_v8_blend_base_softbin_60_40.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20dd8076",
      "metadata": {},
      "source": [
        "## 6) Gated blend (row-wise)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "f84d0366",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "p_test(test) q50/q70/q85: (np.float64(0.32782365731136753), np.float64(0.4123312768067911), np.float64(0.5313312422923425))\n",
            "Saved: submission_v8_gated_base_sub50_sigmoid.csv\n",
            "Saved: submission_v8_gated_base_sub50_sigmoid_sharp.csv\n"
          ]
        }
      ],
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "q50, q70, q85 = np.quantile(p_test_test, [0.5, 0.7, 0.85])\n",
        "print('p_test(test) q50/q70/q85:', (q50, q70, q85))\n",
        "\n",
        "t0 = float(q70)\n",
        "temp = 0.06\n",
        "alpha = sigmoid((p_test_test - t0) / temp)\n",
        "pred_v8_gated = (1 - alpha) * pred_v8_base + alpha * pred_v8_sub50\n",
        "pd.DataFrame({'id': test_ids, TARGET: pred_v8_gated}).to_csv('submission_v8_gated_base_sub50_sigmoid.csv', index=False)\n",
        "print('Saved: submission_v8_gated_base_sub50_sigmoid.csv')\n",
        "\n",
        "temp2 = 0.04\n",
        "alpha2 = sigmoid((p_test_test - t0) / temp2)\n",
        "pred_v8_gated2 = (1 - alpha2) * pred_v8_base + alpha2 * pred_v8_sub50\n",
        "pd.DataFrame({'id': test_ids, TARGET: pred_v8_gated2}).to_csv('submission_v8_gated_base_sub50_sigmoid_sharp.csv', index=False)\n",
        "print('Saved: submission_v8_gated_base_sub50_sigmoid_sharp.csv')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
