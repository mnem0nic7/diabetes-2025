{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "220eef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "N_SPLITS = 10\n",
    "TARGET = 'diagnosed_diabetes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5418f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (700000, 26)\n",
      "Test shape: (300000, 25)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "\n",
    "test_ids = test['id']\n",
    "train_ids = train['id']\n",
    "train = train.drop(columns=['id'])\n",
    "test = test.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76be2515",
   "metadata": {},
   "source": [
    "## Part 1: Submission Blending\n",
    "\n",
    "Blend the best performing submissions to potentially get a better result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "003223b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded V1: LB=0.69720\n",
      "Loaded V2: LB=0.69714\n",
      "Loaded V3: LB=0.69668\n",
      "Loaded V4: LB=0.69484\n",
      "Loaded V4_raw: LB=0.69560\n",
      "Loaded V5_LGB: LB=0.69771\n",
      "Loaded V5_CAT: LB=0.69585\n",
      "\n",
      "Loaded 7 submissions\n"
     ]
    }
   ],
   "source": [
    "# Load existing submissions\n",
    "submissions = {}\n",
    "submission_files = [\n",
    "    ('submission.csv', 'V1', 0.69720),\n",
    "    ('submission_v2.csv', 'V2', 0.69714),\n",
    "    ('submission_v3.csv', 'V3', 0.69668),\n",
    "    ('submission_v4.csv', 'V4', 0.69484),\n",
    "    ('submission_v4_raw.csv', 'V4_raw', 0.69560),\n",
    "    ('submission_v5_lgb_simple.csv', 'V5_LGB', 0.69771),\n",
    "    ('submission_v5_catboost.csv', 'V5_CAT', 0.69585),\n",
    "]\n",
    "\n",
    "for filename, name, lb_score in submission_files:\n",
    "    if os.path.exists(filename):\n",
    "        submissions[name] = {\n",
    "            'data': pd.read_csv(filename),\n",
    "            'lb_score': lb_score\n",
    "        }\n",
    "        print(f\"Loaded {name}: LB={lb_score:.5f}\")\n",
    "\n",
    "print(f\"\\nLoaded {len(submissions)} submissions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bd6a64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Creating Blended Submissions ===\n",
      "Created: submission_v6_blend_top2.csv (V5_LGB + V1, 50/50)\n",
      "Created: submission_v6_blend_top3.csv (V5_LGB=40% + V1=30% + V2=30%)\n",
      "Created: submission_v6_blend_all.csv (LB-weighted blend of 7 submissions)\n"
     ]
    }
   ],
   "source": [
    "# Create blended submissions\n",
    "print(\"\\n=== Creating Blended Submissions ===\")\n",
    "\n",
    "# Blend 1: Top 2 LB scores (V5_LGB + V1)\n",
    "if 'V5_LGB' in submissions and 'V1' in submissions:\n",
    "    blend_top2 = (\n",
    "        submissions['V5_LGB']['data']['diagnosed_diabetes'] * 0.5 +\n",
    "        submissions['V1']['data']['diagnosed_diabetes'] * 0.5\n",
    "    )\n",
    "    sub_blend_top2 = pd.DataFrame({'id': test_ids, 'diagnosed_diabetes': blend_top2})\n",
    "    sub_blend_top2.to_csv('submission_v6_blend_top2.csv', index=False)\n",
    "    print(\"Created: submission_v6_blend_top2.csv (V5_LGB + V1, 50/50)\")\n",
    "\n",
    "# Blend 2: Top 3 LB scores\n",
    "if all(k in submissions for k in ['V5_LGB', 'V1', 'V2']):\n",
    "    blend_top3 = (\n",
    "        submissions['V5_LGB']['data']['diagnosed_diabetes'] * 0.4 +\n",
    "        submissions['V1']['data']['diagnosed_diabetes'] * 0.3 +\n",
    "        submissions['V2']['data']['diagnosed_diabetes'] * 0.3\n",
    "    )\n",
    "    sub_blend_top3 = pd.DataFrame({'id': test_ids, 'diagnosed_diabetes': blend_top3})\n",
    "    sub_blend_top3.to_csv('submission_v6_blend_top3.csv', index=False)\n",
    "    print(\"Created: submission_v6_blend_top3.csv (V5_LGB=40% + V1=30% + V2=30%)\")\n",
    "\n",
    "# Blend 3: All submissions with LB-weighted average\n",
    "if len(submissions) > 0:\n",
    "    # Higher LB score = higher weight (inverse of score since lower is worse)\n",
    "    total_weight = 0\n",
    "    blend_all = np.zeros(len(test_ids))\n",
    "    for name, sub in submissions.items():\n",
    "        weight = sub['lb_score']  # Use LB score as weight\n",
    "        blend_all += sub['data']['diagnosed_diabetes'].values * weight\n",
    "        total_weight += weight\n",
    "    blend_all /= total_weight\n",
    "    \n",
    "    sub_blend_all = pd.DataFrame({'id': test_ids, 'diagnosed_diabetes': blend_all})\n",
    "    sub_blend_all.to_csv('submission_v6_blend_all.csv', index=False)\n",
    "    print(f\"Created: submission_v6_blend_all.csv (LB-weighted blend of {len(submissions)} submissions)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc12af8",
   "metadata": {},
   "source": [
    "## Part 2: Adversarial Weighted Training\n",
    "\n",
    "Use adversarial validation to create sample weights that upweight training samples similar to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed7f63d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_simple(df):\n",
    "    \"\"\"Minimal preprocessing - convert object cols to category dtype\"\"\"\n",
    "    df = df.copy()\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].astype('category')\n",
    "    return df\n",
    "\n",
    "train_simple = prepare_data_simple(train.copy())\n",
    "test_simple = prepare_data_simple(test.copy())\n",
    "\n",
    "y = train_simple[TARGET]\n",
    "X = train_simple.drop(columns=[TARGET])\n",
    "X_test = test_simple.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e7f035a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing adversarial weights...\n",
      "Adversarial AUC: 0.63259\n",
      "Weight stats: min=0.559, max=3.746, mean=1.000\n"
     ]
    }
   ],
   "source": [
    "def compute_adversarial_weights(X_train, X_test):\n",
    "    \"\"\"Compute sample weights based on how test-like each training sample is\"\"\"\n",
    "    \n",
    "    # Combine train and test\n",
    "    X_all = pd.concat([X_train, X_test], axis=0, ignore_index=True)\n",
    "    y_domain = np.concatenate([np.zeros(len(X_train)), np.ones(len(X_test))])\n",
    "    \n",
    "    # Train adversarial classifier\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    oof_preds = np.zeros(len(X_all))\n",
    "    \n",
    "    print(\"Computing adversarial weights...\")\n",
    "    for fold, (tr_idx, va_idx) in enumerate(skf.split(X_all, y_domain)):\n",
    "        model = lgb.LGBMClassifier(\n",
    "            n_estimators=500,\n",
    "            learning_rate=0.05,\n",
    "            num_leaves=31,\n",
    "            random_state=SEED,\n",
    "            verbose=-1\n",
    "        )\n",
    "        model.fit(\n",
    "            X_all.iloc[tr_idx], y_domain[tr_idx],\n",
    "            eval_set=[(X_all.iloc[va_idx], y_domain[va_idx])],\n",
    "            callbacks=[lgb.early_stopping(50, verbose=False)]\n",
    "        )\n",
    "        oof_preds[va_idx] = model.predict_proba(X_all.iloc[va_idx])[:, 1]\n",
    "    \n",
    "    adv_auc = roc_auc_score(y_domain, oof_preds)\n",
    "    print(f\"Adversarial AUC: {adv_auc:.5f}\")\n",
    "    \n",
    "    # Convert probabilities to weights\n",
    "    train_probs = oof_preds[:len(X_train)]\n",
    "    weights = (train_probs + 1e-6) / (1 - train_probs + 1e-6)\n",
    "    weights = np.clip(weights, np.percentile(weights, 1), np.percentile(weights, 99))\n",
    "    weights = weights / weights.mean()\n",
    "    \n",
    "    print(f\"Weight stats: min={weights.min():.3f}, max={weights.max():.3f}, mean={weights.mean():.3f}\")\n",
    "    \n",
    "    return weights, adv_auc\n",
    "\n",
    "adv_weights, adv_auc = compute_adversarial_weights(X, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1eb1a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training with Adversarial Weights ===\n",
      "Training LightGBM with adversarial weights (10-fold)...\n",
      "  Fold 1 AUC: 0.72720\n",
      "  Fold 2 AUC: 0.72827\n",
      "  Fold 3 AUC: 0.72623\n",
      "  Fold 4 AUC: 0.72637\n",
      "  Fold 5 AUC: 0.72734\n",
      "  Fold 6 AUC: 0.72730\n",
      "  Fold 7 AUC: 0.72561\n",
      "  Fold 8 AUC: 0.73014\n",
      "  Fold 9 AUC: 0.72958\n",
      "  Fold 10 AUC: 0.72622\n",
      "Overall OOF AUC: 0.72742\n",
      "\n",
      "Saved: submission_v6_adversarial.csv (CV AUC: 0.72742)\n"
     ]
    }
   ],
   "source": [
    "def train_lgb_weighted(X, y, X_test, weights, n_splits=10):\n",
    "    \"\"\"Train LightGBM with adversarial sample weights\"\"\"\n",
    "    \n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'n_estimators': 5000,\n",
    "        'learning_rate': 0.01,\n",
    "        'num_leaves': 31,\n",
    "        'max_depth': 6,\n",
    "        'min_child_samples': 50,\n",
    "        'feature_fraction': 0.7,\n",
    "        'bagging_fraction': 0.7,\n",
    "        'bagging_freq': 5,\n",
    "        'reg_alpha': 0.5,\n",
    "        'reg_lambda': 0.5,\n",
    "        'random_state': SEED,\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "    oof_preds = np.zeros(len(X))\n",
    "    test_preds = np.zeros(len(X_test))\n",
    "    \n",
    "    print(f\"Training LightGBM with adversarial weights ({n_splits}-fold)...\")\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        w_tr = weights[train_idx]\n",
    "        \n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            callbacks=[lgb.early_stopping(100, verbose=False)],\n",
    "            sample_weight=w_tr\n",
    "        )\n",
    "        \n",
    "        oof_preds[val_idx] = model.predict_proba(X_val)[:, 1]\n",
    "        test_preds += model.predict_proba(X_test)[:, 1] / n_splits\n",
    "        \n",
    "        fold_auc = roc_auc_score(y_val, oof_preds[val_idx])\n",
    "        print(f\"  Fold {fold+1} AUC: {fold_auc:.5f}\")\n",
    "    \n",
    "    oof_auc = roc_auc_score(y, oof_preds)\n",
    "    print(f\"Overall OOF AUC: {oof_auc:.5f}\")\n",
    "    \n",
    "    return oof_preds, test_preds, oof_auc\n",
    "\n",
    "print(\"\\n=== Training with Adversarial Weights ===\")\n",
    "oof_adv, test_adv, auc_adv = train_lgb_weighted(X, y, X_test, adv_weights, n_splits=N_SPLITS)\n",
    "\n",
    "# Save submission\n",
    "sub_adv = pd.DataFrame({'id': test_ids, 'diagnosed_diabetes': test_adv})\n",
    "sub_adv.to_csv('submission_v6_adversarial.csv', index=False)\n",
    "print(f\"\\nSaved: submission_v6_adversarial.csv (CV AUC: {auc_adv:.5f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2dec2c",
   "metadata": {},
   "source": [
    "## Part 3: Pseudo-Labeling\n",
    "\n",
    "Use high-confidence predictions on test data as additional training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5076df7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Pseudo-Labeling (threshold=0.90) ===\n",
      "High-confidence samples (threshold=0.9): 18621 (6.2%)\n",
      "  - Positive: 18418\n",
      "  - Negative: 203\n",
      "Combined training size: 718621 (original: 700000, pseudo: 18621)\n",
      "Training with pseudo-labels (10-fold)...\n",
      "  Fold 1 AUC: 0.72831\n",
      "  Fold 2 AUC: 0.72958\n",
      "  Fold 3 AUC: 0.72716\n",
      "  Fold 4 AUC: 0.72747\n",
      "  Fold 5 AUC: 0.72854\n",
      "  Fold 6 AUC: 0.72859\n",
      "  Fold 7 AUC: 0.72705\n",
      "  Fold 8 AUC: 0.73125\n",
      "  Fold 9 AUC: 0.73052\n",
      "  Fold 10 AUC: 0.72752\n",
      "Overall OOF AUC: 0.72860\n",
      "Saved: submission_v6_pseudo_90.csv (CV AUC: 0.72860)\n"
     ]
    }
   ],
   "source": [
    "def train_with_pseudo_labels(X, y, X_test, initial_preds, confidence_threshold=0.9, n_splits=10):\n",
    "    \"\"\"\n",
    "    Train with pseudo-labeling:\n",
    "    1. Use initial predictions to identify high-confidence test samples\n",
    "    2. Add these as training data with their predicted labels\n",
    "    3. Retrain the model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Identify high-confidence samples\n",
    "    high_conf_pos = initial_preds >= confidence_threshold  # Confident positive\n",
    "    high_conf_neg = initial_preds <= (1 - confidence_threshold)  # Confident negative\n",
    "    high_conf_mask = high_conf_pos | high_conf_neg\n",
    "    \n",
    "    n_pseudo = high_conf_mask.sum()\n",
    "    print(f\"High-confidence samples (threshold={confidence_threshold}): {n_pseudo} ({100*n_pseudo/len(X_test):.1f}%)\")\n",
    "    print(f\"  - Positive: {high_conf_pos.sum()}\")\n",
    "    print(f\"  - Negative: {high_conf_neg.sum()}\")\n",
    "    \n",
    "    if n_pseudo == 0:\n",
    "        print(\"No high-confidence samples found. Skipping pseudo-labeling.\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Create pseudo-labeled data\n",
    "    X_pseudo = X_test[high_conf_mask].copy()\n",
    "    y_pseudo = (initial_preds[high_conf_mask] >= 0.5).astype(float)\n",
    "    \n",
    "    # Combine original training data with pseudo-labeled data\n",
    "    X_combined = pd.concat([X, X_pseudo], axis=0, ignore_index=True)\n",
    "    y_combined = pd.concat([y, pd.Series(y_pseudo)], axis=0, ignore_index=True)\n",
    "    \n",
    "    print(f\"Combined training size: {len(X_combined)} (original: {len(X)}, pseudo: {n_pseudo})\")\n",
    "    \n",
    "    # Train on combined data\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'n_estimators': 5000,\n",
    "        'learning_rate': 0.01,\n",
    "        'num_leaves': 31,\n",
    "        'max_depth': 6,\n",
    "        'min_child_samples': 50,\n",
    "        'feature_fraction': 0.7,\n",
    "        'bagging_fraction': 0.7,\n",
    "        'bagging_freq': 5,\n",
    "        'reg_alpha': 0.5,\n",
    "        'reg_lambda': 0.5,\n",
    "        'random_state': SEED,\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "    oof_preds = np.zeros(len(X))  # OOF only for original data\n",
    "    test_preds = np.zeros(len(X_test))\n",
    "    \n",
    "    print(f\"Training with pseudo-labels ({n_splits}-fold)...\")\n",
    "    \n",
    "    # We need to be careful - only validate on original data\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        # Get original data splits\n",
    "        X_tr_orig = X.iloc[train_idx]\n",
    "        y_tr_orig = y.iloc[train_idx]\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_val = y.iloc[val_idx]\n",
    "        \n",
    "        # Add all pseudo-labeled data to training\n",
    "        X_tr = pd.concat([X_tr_orig, X_pseudo], axis=0, ignore_index=True)\n",
    "        y_tr = pd.concat([y_tr_orig, pd.Series(y_pseudo)], axis=0, ignore_index=True)\n",
    "        \n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            callbacks=[lgb.early_stopping(100, verbose=False)]\n",
    "        )\n",
    "        \n",
    "        oof_preds[val_idx] = model.predict_proba(X_val)[:, 1]\n",
    "        test_preds += model.predict_proba(X_test)[:, 1] / n_splits\n",
    "        \n",
    "        fold_auc = roc_auc_score(y_val, oof_preds[val_idx])\n",
    "        print(f\"  Fold {fold+1} AUC: {fold_auc:.5f}\")\n",
    "    \n",
    "    oof_auc = roc_auc_score(y, oof_preds)\n",
    "    print(f\"Overall OOF AUC: {oof_auc:.5f}\")\n",
    "    \n",
    "    return oof_preds, test_preds, oof_auc\n",
    "\n",
    "# Use our best submission as initial predictions for pseudo-labeling\n",
    "if 'V5_LGB' in submissions:\n",
    "    initial_preds = submissions['V5_LGB']['data']['diagnosed_diabetes'].values\n",
    "    \n",
    "    print(\"\\n=== Pseudo-Labeling (threshold=0.90) ===\")\n",
    "    oof_pseudo_90, test_pseudo_90, auc_pseudo_90 = train_with_pseudo_labels(\n",
    "        X, y, X_test, initial_preds, confidence_threshold=0.90, n_splits=N_SPLITS\n",
    "    )\n",
    "    \n",
    "    if test_pseudo_90 is not None:\n",
    "        sub_pseudo_90 = pd.DataFrame({'id': test_ids, 'diagnosed_diabetes': test_pseudo_90})\n",
    "        sub_pseudo_90.to_csv('submission_v6_pseudo_90.csv', index=False)\n",
    "        print(f\"Saved: submission_v6_pseudo_90.csv (CV AUC: {auc_pseudo_90:.5f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d80b6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Pseudo-Labeling (threshold=0.85) ===\n",
      "High-confidence samples (threshold=0.85): 37119 (12.4%)\n",
      "  - Positive: 35617\n",
      "  - Negative: 1502\n",
      "Combined training size: 737119 (original: 700000, pseudo: 37119)\n",
      "Training with pseudo-labels (10-fold)...\n",
      "  Fold 1 AUC: 0.72818\n",
      "  Fold 2 AUC: 0.72947\n",
      "  Fold 3 AUC: 0.72706\n",
      "  Fold 4 AUC: 0.72748\n",
      "  Fold 5 AUC: 0.72846\n",
      "  Fold 6 AUC: 0.72846\n",
      "  Fold 7 AUC: 0.72686\n",
      "  Fold 8 AUC: 0.73130\n",
      "  Fold 9 AUC: 0.73049\n",
      "  Fold 10 AUC: 0.72739\n",
      "Overall OOF AUC: 0.72851\n",
      "Saved: submission_v6_pseudo_85.csv (CV AUC: 0.72851)\n"
     ]
    }
   ],
   "source": [
    "# Try with lower confidence threshold\n",
    "if 'V5_LGB' in submissions:\n",
    "    print(\"\\n=== Pseudo-Labeling (threshold=0.85) ===\")\n",
    "    oof_pseudo_85, test_pseudo_85, auc_pseudo_85 = train_with_pseudo_labels(\n",
    "        X, y, X_test, initial_preds, confidence_threshold=0.85, n_splits=N_SPLITS\n",
    "    )\n",
    "    \n",
    "    if test_pseudo_85 is not None:\n",
    "        sub_pseudo_85 = pd.DataFrame({'id': test_ids, 'diagnosed_diabetes': test_pseudo_85})\n",
    "        sub_pseudo_85.to_csv('submission_v6_pseudo_85.csv', index=False)\n",
    "        print(f\"Saved: submission_v6_pseudo_85.csv (CV AUC: {auc_pseudo_85:.5f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa6e7df",
   "metadata": {},
   "source": [
    "## Part 4: Different Ensemble Strategy\n",
    "\n",
    "Try rank averaging instead of probability averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d8a3a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Rank Average Ensemble ===\n",
      "Saved: submission_v6_rank_blend.csv (rank average of 7 submissions)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import rankdata\n",
    "\n",
    "def rank_average_blend(submission_dict):\n",
    "    \"\"\"Blend submissions using rank averaging instead of probability averaging\"\"\"\n",
    "    ranks = []\n",
    "    for name, sub in submission_dict.items():\n",
    "        preds = sub['data']['diagnosed_diabetes'].values\n",
    "        rank = rankdata(preds) / len(preds)  # Normalize to [0, 1]\n",
    "        ranks.append(rank)\n",
    "    \n",
    "    avg_rank = np.mean(ranks, axis=0)\n",
    "    return avg_rank\n",
    "\n",
    "if len(submissions) > 1:\n",
    "    print(\"\\n=== Rank Average Ensemble ===\")\n",
    "    rank_blend = rank_average_blend(submissions)\n",
    "    \n",
    "    sub_rank = pd.DataFrame({'id': test_ids, 'diagnosed_diabetes': rank_blend})\n",
    "    sub_rank.to_csv('submission_v6_rank_blend.csv', index=False)\n",
    "    print(f\"Saved: submission_v6_rank_blend.csv (rank average of {len(submissions)} submissions)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25583bbd",
   "metadata": {},
   "source": [
    "## Part 5: Train with More Regularization\n",
    "\n",
    "Try even more aggressive regularization since CV-LB gap suggests overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fc3b867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ultra-Conservative Model ===\n",
      "Training Ultra-Conservative LightGBM (10-fold)...\n",
      "  Fold 1 AUC: 0.71851\n",
      "  Fold 2 AUC: 0.71978\n",
      "  Fold 3 AUC: 0.71766\n",
      "  Fold 4 AUC: 0.71645\n",
      "  Fold 5 AUC: 0.71887\n",
      "  Fold 6 AUC: 0.71746\n",
      "  Fold 7 AUC: 0.71659\n",
      "  Fold 8 AUC: 0.72097\n",
      "  Fold 9 AUC: 0.72099\n",
      "  Fold 10 AUC: 0.71692\n",
      "Overall OOF AUC: 0.71841\n",
      "Saved: submission_v6_ultra_conservative.csv (CV AUC: 0.71841)\n"
     ]
    }
   ],
   "source": [
    "def train_lgb_ultra_conservative(X, y, X_test, n_splits=10):\n",
    "    \"\"\"Train with very aggressive regularization\"\"\"\n",
    "    \n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'n_estimators': 3000,\n",
    "        'learning_rate': 0.005,  # Even lower\n",
    "        'num_leaves': 15,  # Much fewer leaves\n",
    "        'max_depth': 4,  # Shallower\n",
    "        'min_child_samples': 100,  # More samples per leaf\n",
    "        'feature_fraction': 0.5,\n",
    "        'bagging_fraction': 0.6,\n",
    "        'bagging_freq': 5,\n",
    "        'reg_alpha': 2.0,  # Strong L1\n",
    "        'reg_lambda': 2.0,  # Strong L2\n",
    "        'min_gain_to_split': 0.1,  # Need more gain to split\n",
    "        'random_state': SEED,\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "    oof_preds = np.zeros(len(X))\n",
    "    test_preds = np.zeros(len(X_test))\n",
    "    \n",
    "    print(f\"Training Ultra-Conservative LightGBM ({n_splits}-fold)...\")\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            callbacks=[lgb.early_stopping(100, verbose=False)]\n",
    "        )\n",
    "        \n",
    "        oof_preds[val_idx] = model.predict_proba(X_val)[:, 1]\n",
    "        test_preds += model.predict_proba(X_test)[:, 1] / n_splits\n",
    "        \n",
    "        fold_auc = roc_auc_score(y_val, oof_preds[val_idx])\n",
    "        print(f\"  Fold {fold+1} AUC: {fold_auc:.5f}\")\n",
    "    \n",
    "    oof_auc = roc_auc_score(y, oof_preds)\n",
    "    print(f\"Overall OOF AUC: {oof_auc:.5f}\")\n",
    "    \n",
    "    return oof_preds, test_preds, oof_auc\n",
    "\n",
    "print(\"\\n=== Ultra-Conservative Model ===\")\n",
    "oof_ultra, test_ultra, auc_ultra = train_lgb_ultra_conservative(X, y, X_test, n_splits=N_SPLITS)\n",
    "\n",
    "sub_ultra = pd.DataFrame({'id': test_ids, 'diagnosed_diabetes': test_ultra})\n",
    "sub_ultra.to_csv('submission_v6_ultra_conservative.csv', index=False)\n",
    "print(f\"Saved: submission_v6_ultra_conservative.csv (CV AUC: {auc_ultra:.5f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae5602c",
   "metadata": {},
   "source": [
    "## Part 6: Domain-Shift Tactics (New)\n",
    "\n",
    "These aim to reduce the CV→LB gap caused by train/test distribution shift:\n",
    "\n",
    "1. **Shift-feature dropping**: identify features that best separate train vs test, then drop the most-shifted.\n",
    "2. **Train on most test-like rows**: only train on the subset of training rows that look most like the test distribution.\n",
    "3. **Numeric distribution alignment**: quantile-transform numeric features using train+test (unsupervised)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf4993bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "def train_lgb_generic(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    X_test: pd.DataFrame,\n",
    "    n_splits: int = 10,\n",
    "    sample_weight: np.ndarray | None = None,\n",
    "    seed: int = 42,\n",
    "    params: dict | None = None,\n",
    "):\n",
    "    if params is None:\n",
    "        params = {\n",
    "            'objective': 'binary',\n",
    "            'metric': 'auc',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'n_estimators': 5000,\n",
    "            'learning_rate': 0.01,\n",
    "            'num_leaves': 31,\n",
    "            'max_depth': 6,\n",
    "            'min_child_samples': 50,\n",
    "            'feature_fraction': 0.7,\n",
    "            'bagging_fraction': 0.7,\n",
    "            'bagging_freq': 5,\n",
    "            'reg_alpha': 0.5,\n",
    "            'reg_lambda': 0.5,\n",
    "            'random_state': seed,\n",
    "            'verbose': -1,\n",
    "        }\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    oof_preds = np.zeros(len(X_train))\n",
    "    test_preds = np.zeros(len(X_test))\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "        X_tr, X_va = X_train.iloc[tr_idx], X_train.iloc[va_idx]\n",
    "        y_tr, y_va = y_train.iloc[tr_idx], y_train.iloc[va_idx]\n",
    "        w_tr = sample_weight[tr_idx] if sample_weight is not None else None\n",
    "\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(\n",
    "            X_tr,\n",
    "            y_tr,\n",
    "            eval_set=[(X_va, y_va)],\n",
    "            callbacks=[lgb.early_stopping(100, verbose=False)],\n",
    "            sample_weight=w_tr,\n",
    "        )\n",
    "\n",
    "        oof_preds[va_idx] = model.predict_proba(X_va)[:, 1]\n",
    "        test_preds += model.predict_proba(X_test)[:, 1] / n_splits\n",
    "\n",
    "    oof_auc = roc_auc_score(y_train, oof_preds)\n",
    "    return oof_preds, test_preds, oof_auc\n",
    "\n",
    "\n",
    "def compute_domain_shift_importance(X_train: pd.DataFrame, X_test: pd.DataFrame, n_splits: int = 5, seed: int = 42):\n",
    "    \"\"\"Train a domain classifier (train=0, test=1) and return mean gain importances.\"\"\"\n",
    "    X_all = pd.concat([X_train, X_test], axis=0, ignore_index=True)\n",
    "    y_domain = np.concatenate([np.zeros(len(X_train)), np.ones(len(X_test))])\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    importances = []\n",
    "    oof = np.zeros(len(X_all))\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(skf.split(X_all, y_domain)):\n",
    "        X_tr, X_va = X_all.iloc[tr_idx], X_all.iloc[va_idx]\n",
    "        y_tr, y_va = y_domain[tr_idx], y_domain[va_idx]\n",
    "\n",
    "        dom = lgb.LGBMClassifier(\n",
    "            n_estimators=800,\n",
    "            learning_rate=0.05,\n",
    "            num_leaves=63,\n",
    "            min_child_samples=50,\n",
    "            feature_fraction=0.8,\n",
    "            bagging_fraction=0.8,\n",
    "            bagging_freq=5,\n",
    "            random_state=seed + fold,\n",
    "            verbose=-1,\n",
    "        )\n",
    "        dom.fit(\n",
    "            X_tr,\n",
    "            y_tr,\n",
    "            eval_set=[(X_va, y_va)],\n",
    "            callbacks=[lgb.early_stopping(80, verbose=False)],\n",
    "        )\n",
    "\n",
    "        oof[va_idx] = dom.predict_proba(X_va)[:, 1]\n",
    "        booster = dom.booster_\n",
    "        gain = booster.feature_importance(importance_type='gain')\n",
    "        importances.append(gain)\n",
    "\n",
    "    auc = roc_auc_score(y_domain, oof)\n",
    "    mean_gain = np.mean(np.vstack(importances), axis=0)\n",
    "    imp = pd.DataFrame({'feature': X_all.columns, 'gain': mean_gain}).sort_values('gain', ascending=False)\n",
    "    return imp, auc\n",
    "\n",
    "\n",
    "def compute_testlikeness_scores(X_train: pd.DataFrame, X_test: pd.DataFrame, n_splits: int = 5, seed: int = 42):\n",
    "    \"\"\"Return p(test|x) for each training row (higher => more test-like).\"\"\"\n",
    "    X_all = pd.concat([X_train, X_test], axis=0, ignore_index=True)\n",
    "    y_domain = np.concatenate([np.zeros(len(X_train)), np.ones(len(X_test))])\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    oof = np.zeros(len(X_all))\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(skf.split(X_all, y_domain)):\n",
    "        X_tr, X_va = X_all.iloc[tr_idx], X_all.iloc[va_idx]\n",
    "        y_tr, y_va = y_domain[tr_idx], y_domain[va_idx]\n",
    "\n",
    "        dom = lgb.LGBMClassifier(\n",
    "            n_estimators=800,\n",
    "            learning_rate=0.05,\n",
    "            num_leaves=63,\n",
    "            min_child_samples=50,\n",
    "            feature_fraction=0.8,\n",
    "            bagging_fraction=0.8,\n",
    "            bagging_freq=5,\n",
    "            random_state=seed + 100 + fold,\n",
    "            verbose=-1,\n",
    "        )\n",
    "        dom.fit(\n",
    "            X_tr,\n",
    "            y_tr,\n",
    "            eval_set=[(X_va, y_va)],\n",
    "            callbacks=[lgb.early_stopping(80, verbose=False)],\n",
    "        )\n",
    "        oof[va_idx] = dom.predict_proba(X_va)[:, 1]\n",
    "\n",
    "    auc = roc_auc_score(y_domain, oof)\n",
    "    train_scores = oof[: len(X_train)]\n",
    "    return train_scores, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784cee8c",
   "metadata": {},
   "source": [
    "### 6.1 Shift-feature dropping\n",
    "\n",
    "Idea: if a feature mostly helps distinguish train vs test, it can encourage learning spurious train-only patterns.\n",
    "\n",
    "We’ll compute domain-model importances and drop the most-shifted features at a few cutoffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d2aa855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain AUC (feature-shift model): 0.64125\n",
      "\n",
      "Top shifted features:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "feature",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gain",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "1b3fed9a-b2a6-404e-80b4-36064dc7cfa0",
       "rows": [
        [
         "2",
         "physical_activity_minutes_per_week",
         "194870.286329937"
        ],
        [
         "14",
         "triglycerides",
         "118628.28364949227"
        ],
        [
         "6",
         "bmi",
         "70277.44644422531"
        ],
        [
         "11",
         "cholesterol_total",
         "66719.26503920555"
        ],
        [
         "10",
         "heart_rate",
         "44523.69221343994"
        ],
        [
         "13",
         "ldl_cholesterol",
         "40157.676689863205"
        ],
        [
         "0",
         "age",
         "34998.29731416702"
        ],
        [
         "8",
         "systolic_bp",
         "30760.60745296478"
        ],
        [
         "5",
         "screen_time_hours_per_day",
         "25906.422665023805"
        ],
        [
         "12",
         "hdl_cholesterol",
         "25886.692568016053"
        ],
        [
         "3",
         "diet_score",
         "24785.46083102226"
        ],
        [
         "7",
         "waist_to_hip_ratio",
         "24669.922278404236"
        ],
        [
         "9",
         "diastolic_bp",
         "20266.8951859951"
        ],
        [
         "4",
         "sleep_hours_per_day",
         "19652.005838871002"
        ],
        [
         "1",
         "alcohol_consumption_per_week",
         "9024.290519857406"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 15
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>physical_activity_minutes_per_week</td>\n",
       "      <td>194870.286330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>triglycerides</td>\n",
       "      <td>118628.283649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bmi</td>\n",
       "      <td>70277.446444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cholesterol_total</td>\n",
       "      <td>66719.265039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>heart_rate</td>\n",
       "      <td>44523.692213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ldl_cholesterol</td>\n",
       "      <td>40157.676690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>34998.297314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>systolic_bp</td>\n",
       "      <td>30760.607453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>screen_time_hours_per_day</td>\n",
       "      <td>25906.422665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hdl_cholesterol</td>\n",
       "      <td>25886.692568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>diet_score</td>\n",
       "      <td>24785.460831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>waist_to_hip_ratio</td>\n",
       "      <td>24669.922278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>diastolic_bp</td>\n",
       "      <td>20266.895186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sleep_hours_per_day</td>\n",
       "      <td>19652.005839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alcohol_consumption_per_week</td>\n",
       "      <td>9024.290520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               feature           gain\n",
       "2   physical_activity_minutes_per_week  194870.286330\n",
       "14                       triglycerides  118628.283649\n",
       "6                                  bmi   70277.446444\n",
       "11                   cholesterol_total   66719.265039\n",
       "10                          heart_rate   44523.692213\n",
       "13                     ldl_cholesterol   40157.676690\n",
       "0                                  age   34998.297314\n",
       "8                          systolic_bp   30760.607453\n",
       "5            screen_time_hours_per_day   25906.422665\n",
       "12                     hdl_cholesterol   25886.692568\n",
       "3                           diet_score   24785.460831\n",
       "7                   waist_to_hip_ratio   24669.922278\n",
       "9                         diastolic_bp   20266.895186\n",
       "4                  sleep_hours_per_day   19652.005839\n",
       "1         alcohol_consumption_per_week    9024.290520"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped top 3 shifted feats -> CV AUC 0.66962 | saved submission_v6_drop_shift_top3.csv\n",
      "Dropped top 5 shifted feats -> CV AUC 0.66773 | saved submission_v6_drop_shift_top5.csv\n"
     ]
    }
   ],
   "source": [
    "shift_imp, shift_auc = compute_domain_shift_importance(X, X_test, n_splits=5, seed=SEED)\n",
    "print(f\"Domain AUC (feature-shift model): {shift_auc:.5f}\")\n",
    "\n",
    "print(\"\\nTop shifted features:\")\n",
    "display(shift_imp.head(15))\n",
    "\n",
    "# QUICK grid (keeps runtime reasonable). Expand if these look promising.\n",
    "quick = True\n",
    "k_list = [3, 5] if quick else [1, 2, 3, 5, 8]\n",
    "\n",
    "for k in k_list:\n",
    "    drop_feats = shift_imp['feature'].head(k).tolist()\n",
    "    cols = [c for c in X.columns if c not in drop_feats]\n",
    "\n",
    "    oof, preds, auc = train_lgb_generic(X[cols], y, X_test[cols], n_splits=N_SPLITS, seed=SEED)\n",
    "    out = f\"submission_v6_drop_shift_top{k}.csv\"\n",
    "    pd.DataFrame({'id': test_ids, 'diagnosed_diabetes': preds}).to_csv(out, index=False)\n",
    "    print(f\"Dropped top {k} shifted feats -> CV AUC {auc:.5f} | saved {out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac14017",
   "metadata": {},
   "source": [
    "### 6.2 Train only on most test-like rows\n",
    "\n",
    "Idea: if the test set is drawn from a different mixture of subpopulations, training on the most test-like slice can reduce mismatch.\n",
    "\n",
    "We compute a test-likeness score $p(\\text{test}|x)$ via a domain classifier and train on the top percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69c488f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain AUC (score model): 0.64113\n",
      "Top 50% test-like -> CV AUC 0.74238 | saved submission_v6_top50pct_testlike.csv\n",
      "Top 50% test-like + weights -> CV AUC 0.74127 | saved submission_v6_top50pct_testlike_weighted.csv\n"
     ]
    }
   ],
   "source": [
    "train_scores, score_auc = compute_testlikeness_scores(X, X_test, n_splits=5, seed=SEED)\n",
    "print(f\"Domain AUC (score model): {score_auc:.5f}\")\n",
    "\n",
    "# QUICK grid (keeps runtime reasonable). Expand if these look promising.\n",
    "quick = True\n",
    "pct_list = [0.50] if quick else [0.30, 0.50, 0.70]\n",
    "order = np.argsort(train_scores)  # ascending\n",
    "\n",
    "for pct in pct_list:\n",
    "    k = int(len(order) * pct)\n",
    "    idx = order[-k:]\n",
    "\n",
    "    X_sub = X.iloc[idx].reset_index(drop=True)\n",
    "    y_sub = y.iloc[idx].reset_index(drop=True)\n",
    "\n",
    "    # Option A: no weights\n",
    "    oof, preds, auc = train_lgb_generic(X_sub, y_sub, X_test, n_splits=N_SPLITS, seed=SEED)\n",
    "    out = f\"submission_v6_top{int(pct*100)}pct_testlike.csv\"\n",
    "    pd.DataFrame({'id': test_ids, 'diagnosed_diabetes': preds}).to_csv(out, index=False)\n",
    "    print(f\"Top {int(pct*100)}% test-like -> CV AUC {auc:.5f} | saved {out}\")\n",
    "\n",
    "for pct in pct_list:\n",
    "    k = int(len(order) * pct)\n",
    "    idx = order[-k:]\n",
    "\n",
    "    X_sub = X.iloc[idx].reset_index(drop=True)\n",
    "    y_sub = y.iloc[idx].reset_index(drop=True)\n",
    "    w_sub = adv_weights[idx]\n",
    "\n",
    "    oof, preds, auc = train_lgb_generic(X_sub, y_sub, X_test, n_splits=N_SPLITS, seed=SEED, sample_weight=w_sub)\n",
    "    out = f\"submission_v6_top{int(pct*100)}pct_testlike_weighted.csv\"\n",
    "    pd.DataFrame({'id': test_ids, 'diagnosed_diabetes': preds}).to_csv(out, index=False)\n",
    "    print(f\"Top {int(pct*100)}% test-like + weights -> CV AUC {auc:.5f} | saved {out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc3112d",
   "metadata": {},
   "source": [
    "### 6.3 Numeric distribution alignment (Quantile transform)\n",
    "\n",
    "Idea: apply a monotonic transform to numeric features so their marginal distributions match better between train and test.\n",
    "\n",
    "This is unsupervised (uses $X$ only), and often helps under covariate shift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51c2647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile-normalized numerics -> CV AUC 0.72856 | saved submission_v6_quantile_norm.csv\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "num_cols = X.select_dtypes(include=['number', 'int64', 'float64']).columns.tolist()\n",
    "cat_cols = [c for c in X.columns if c not in num_cols]\n",
    "\n",
    "# Fit transform on combined train+test numerics (subsample for speed)\n",
    "qt = QuantileTransformer(\n",
    "    n_quantiles=2000,\n",
    "    output_distribution='normal',\n",
    "    subsample=200_000,\n",
    "    random_state=SEED,\n",
    ")\n",
    "\n",
    "X_num_all = pd.concat([X[num_cols], X_test[num_cols]], axis=0, ignore_index=True)\n",
    "qt.fit(X_num_all)\n",
    "\n",
    "X_q = X.copy()\n",
    "X_test_q = X_test.copy()\n",
    "X_q[num_cols] = qt.transform(X[num_cols])\n",
    "X_test_q[num_cols] = qt.transform(X_test[num_cols])\n",
    "\n",
    "# Keep categoricals as-is\n",
    "for c in cat_cols:\n",
    "    if str(X_q[c].dtype) == 'category':\n",
    "        continue\n",
    "\n",
    "oof, preds, auc = train_lgb_generic(X_q, y, X_test_q, n_splits=N_SPLITS, seed=SEED)\n",
    "out = 'submission_v6_quantile_norm.csv'\n",
    "pd.DataFrame({'id': test_ids, 'diagnosed_diabetes': preds}).to_csv(out, index=False)\n",
    "print(f\"Quantile-normalized numerics -> CV AUC {auc:.5f} | saved {out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066d67e8",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4720b127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "V6 SUBMISSIONS READY FOR APPROVAL\n",
      "============================================================\n",
      "\n",
      "Submissions created:\n",
      "  1. submission_v6_blend_top2.csv\n",
      "     → Blend V5_LGB + V1 (50/50)\n",
      "  2. submission_v6_blend_top3.csv\n",
      "     → Blend V5_LGB + V1 + V2\n",
      "  3. submission_v6_blend_all.csv\n",
      "     → LB-weighted blend of all\n",
      "  4. submission_v6_adversarial.csv\n",
      "     → Adversarial weights (CV: 0.72742)\n",
      "  5. submission_v6_rank_blend.csv\n",
      "     → Rank average blend\n",
      "  6. submission_v6_ultra_conservative.csv\n",
      "     → Ultra-conservative (CV: 0.71841)\n",
      "  7. submission_v6_pseudo_90.csv\n",
      "     → Pseudo-label 90% (CV: 0.72860)\n",
      "  8. submission_v6_pseudo_85.csv\n",
      "     → Pseudo-label 85% (CV: 0.72851)\n",
      "\n",
      "============================================================\n",
      "WAITING FOR YOUR APPROVAL TO SUBMIT\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"V6 SUBMISSIONS READY FOR APPROVAL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "v6_submissions = [\n",
    "    ('submission_v6_blend_top2.csv', 'Blend V5_LGB + V1 (50/50)'),\n",
    "    ('submission_v6_blend_top3.csv', 'Blend V5_LGB + V1 + V2'),\n",
    "    ('submission_v6_blend_all.csv', 'LB-weighted blend of all'),\n",
    "    ('submission_v6_adversarial.csv', f'Adversarial weights (CV: {auc_adv:.5f})'),\n",
    "    ('submission_v6_rank_blend.csv', 'Rank average blend'),\n",
    "    ('submission_v6_ultra_conservative.csv', f'Ultra-conservative (CV: {auc_ultra:.5f})'),\n",
    "]\n",
    "\n",
    "if 'auc_pseudo_90' in dir() and auc_pseudo_90 is not None:\n",
    "    v6_submissions.append(('submission_v6_pseudo_90.csv', f'Pseudo-label 90% (CV: {auc_pseudo_90:.5f})'))\n",
    "if 'auc_pseudo_85' in dir() and auc_pseudo_85 is not None:\n",
    "    v6_submissions.append(('submission_v6_pseudo_85.csv', f'Pseudo-label 85% (CV: {auc_pseudo_85:.5f})'))\n",
    "\n",
    "print(\"\\nSubmissions created:\")\n",
    "for i, (filename, desc) in enumerate(v6_submissions, 1):\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"  {i}. {filename}\")\n",
    "        print(f\"     → {desc}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"WAITING FOR YOUR APPROVAL TO SUBMIT\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
