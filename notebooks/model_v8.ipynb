{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e094771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, StratifiedGroupKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "N_SPLITS = 10\n",
    "TARGET = 'diagnosed_diabetes'\n",
    "COMP = 'playground-series-s5e12'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19028ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedGroupKFold, KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "N_SPLITS = 10\n",
    "TARGET = 'diagnosed_diabetes'\n",
    "DATA_DIR = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ec3909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(DATA_DIR, 'test.csv'))\n",
    "\n",
    "print('Train shape:', train.shape)\n",
    "print('Test shape :', test.shape)\n",
    "print('Target rate:', train[TARGET].mean())\n",
    "\n",
    "test_ids = test['id']\n",
    "train = train.drop(columns=['id'])\n",
    "test = test.drop(columns=['id'])\n",
    "\n",
    "def to_category(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    for c in out.columns:\n",
    "        if out[c].dtype == 'object':\n",
    "            out[c] = out[c].astype('category')\n",
    "    return out\n",
    "\n",
    "train = to_category(train)\n",
    "test = to_category(test)\n",
    "\n",
    "y = train[TARGET].astype(int)\n",
    "X = train.drop(columns=[TARGET])\n",
    "X_test = test.copy()\n",
    "\n",
    "cat_cols = X.select_dtypes(include=['category']).columns.tolist()\n",
    "print('Categorical cols:', cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3a31f1",
   "metadata": {},
   "source": [
    "## 1) Domain classifier → test-likeness score\n",
    "\n",
    "We learn `p_test(x) = P(is_test=1 | x)` using a domain classifier (train vs test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c36e9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_domain_classifier_get_p_test(X_train: pd.DataFrame, X_test: pd.DataFrame, seed: int = 42):\n",
    "    X_all = pd.concat([X_train, X_test], axis=0, ignore_index=True)\n",
    "    y_dom = np.concatenate([np.zeros(len(X_train), dtype=int), np.ones(len(X_test), dtype=int)])\n",
    "\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'n_estimators': 4000,\n",
    "        'learning_rate': 0.02,\n",
    "        'num_leaves': 63,\n",
    "        'max_depth': -1,\n",
    "        'min_child_samples': 100,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 1,\n",
    "        'reg_alpha': 0.0,\n",
    "        'reg_lambda': 1.0,\n",
    "        'random_state': seed,\n",
    "        'verbose': -1,\n",
    "    }\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    oof = np.zeros(len(X_all))\n",
    "    for tr, va in kf.split(X_all, y_dom):\n",
    "        m = lgb.LGBMClassifier(**params)\n",
    "        m.fit(\n",
    "            X_all.iloc[tr], y_dom[tr],\n",
    "            eval_set=[(X_all.iloc[va], y_dom[va])],\n",
    "            callbacks=[lgb.early_stopping(100, verbose=False)]\n",
    "        )\n",
    "        oof[va] = m.predict_proba(X_all.iloc[va])[:, 1]\n",
    "\n",
    "    dom_auc = roc_auc_score(y_dom, oof)\n",
    "    print(f'Domain (train vs test) CV AUC: {dom_auc:.5f}')\n",
    "\n",
    "    # fit final model for consistent scoring\n",
    "    final = lgb.LGBMClassifier(**params)\n",
    "    final.fit(X_all, y_dom)\n",
    "    p_all = final.predict_proba(X_all)[:, 1]\n",
    "    p_train = p_all[: len(X_train)]\n",
    "    p_test = p_all[len(X_train):]\n",
    "    return p_train, p_test, dom_auc\n",
    "\n",
    "p_test_train, p_test_test, dom_auc = fit_domain_classifier_get_p_test(X, X_test, seed=SEED)\n",
    "print('p_test(train) quantiles:', np.quantile(p_test_train, [0, 0.1, 0.5, 0.9, 1]))\n",
    "print('p_test(test)  quantiles:', np.quantile(p_test_test, [0, 0.1, 0.5, 0.9, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82429997",
   "metadata": {},
   "source": [
    "## 2) Shift-aware CV metrics\n",
    "\n",
    "We report:\n",
    "- Standard AUC\n",
    "- Weighted AUC using density-ratio weights (proxy for test risk)\n",
    "- AUC on the most test-like slice within each fold (top 30% by `p_test`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91473d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def density_ratio_weights(p: np.ndarray, clip=(0.2, 5.0)):\n",
    "    eps = 1e-6\n",
    "    p = np.clip(p, eps, 1 - eps)\n",
    "    w = p / (1 - p)\n",
    "    w = np.clip(w, clip[0], clip[1])\n",
    "    w = w / np.mean(w)\n",
    "    return w\n",
    "\n",
    "w_train = density_ratio_weights(p_test_train, clip=(0.2, 5.0))\n",
    "print('weights quantiles:', np.quantile(w_train, [0, 0.1, 0.5, 0.9, 1]))\n",
    "\n",
    "def make_shift_groups(p_test: np.ndarray, n_bins: int = 50):\n",
    "    qs = np.quantile(p_test, np.linspace(0, 1, n_bins + 1))\n",
    "    qs = np.unique(qs)\n",
    "    if len(qs) <= 2:\n",
    "        return np.zeros_like(p_test, dtype=int)\n",
    "    groups = np.digitize(p_test, qs[1:-1], right=True)\n",
    "    return groups\n",
    "\n",
    "def weighted_auc(y_true, y_score, sample_weight):\n",
    "    return roc_auc_score(y_true, y_score, sample_weight=sample_weight)\n",
    "\n",
    "def cv_lgb_shift_metrics(\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    X_test: pd.DataFrame,\n",
    "    p_test_train: np.ndarray,\n",
    "    sample_weight: np.ndarray | None = None,\n",
    "    seed: int = 42,\n",
    "    n_splits: int = 10,\n",
    "    use_shift_groups: bool = True,\n",
    "    label: str = 'model',\n",
    "):\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'n_estimators': 8000,\n",
    "        'learning_rate': 0.01,\n",
    "        'num_leaves': 31,\n",
    "        'max_depth': 6,\n",
    "        'min_child_samples': 80,\n",
    "        'feature_fraction': 0.7,\n",
    "        'bagging_fraction': 0.7,\n",
    "        'bagging_freq': 5,\n",
    "        'reg_alpha': 0.5,\n",
    "        'reg_lambda': 0.5,\n",
    "        'random_state': seed,\n",
    "        'verbose': -1,\n",
    "    }\n",
    "\n",
    "    if use_shift_groups:\n",
    "        groups = make_shift_groups(p_test_train, n_bins=50)\n",
    "        splitter = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "        splits = splitter.split(X, y, groups=groups)\n",
    "    else:\n",
    "        splitter = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "        splits = splitter.split(X, y)\n",
    "\n",
    "    oof = np.zeros(len(X))\n",
    "    test_pred = np.zeros(len(X_test))\n",
    "    fold_top = []\n",
    "\n",
    "    w_proxy = density_ratio_weights(p_test_train, clip=(0.2, 5.0))\n",
    "\n",
    "    for tr, va in splits:\n",
    "        X_tr, X_va = X.iloc[tr], X.iloc[va]\n",
    "        y_tr, y_va = y.iloc[tr], y.iloc[va]\n",
    "        fit_w = sample_weight[tr] if sample_weight is not None else None\n",
    "\n",
    "        m = lgb.LGBMClassifier(**params)\n",
    "        m.fit(\n",
    "            X_tr, y_tr,\n",
    "            sample_weight=fit_w,\n",
    "            eval_set=[(X_va, y_va)],\n",
    "            callbacks=[lgb.early_stopping(200, verbose=False)]\n",
    "        )\n",
    "        p_va = m.predict_proba(X_va)[:, 1]\n",
    "        oof[va] = p_va\n",
    "        test_pred += m.predict_proba(X_test)[:, 1] / n_splits\n",
    "\n",
    "        thr = np.quantile(p_test_train[va], 0.70)\n",
    "        idx_top = va[p_test_train[va] >= thr]\n",
    "        if len(idx_top) > 50:\n",
    "            fold_top.append(roc_auc_score(y.iloc[idx_top], oof[idx_top]))\n",
    "        else:\n",
    "            fold_top.append(np.nan)\n",
    "\n",
    "    overall_std = roc_auc_score(y, oof)\n",
    "    overall_w = weighted_auc(y, oof, w_proxy)\n",
    "    overall_top = np.nanmean(fold_top)\n",
    "\n",
    "    print(f'[{label}] CV AUC std: {overall_std:.5f} | weighted: {overall_w:.5f} | val-top30%: {overall_top:.5f}')\n",
    "    return oof, test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0afcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.0: baseline shift-aware model\n",
    "oof_v8_base, pred_v8_base = cv_lgb_shift_metrics(\n",
    "    X, y, X_test, p_test_train,\n",
    "    sample_weight=None, seed=SEED, n_splits=N_SPLITS, use_shift_groups=True,\n",
    "    label='V8_BASE_SHIFT_CV'\n",
    ")\n",
    "pd.DataFrame({'id': test_ids, TARGET: pred_v8_base}).to_csv('submission_v8_base_shiftcv.csv', index=False)\n",
    "print('Saved: submission_v8_base_shiftcv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e2ab60",
   "metadata": {},
   "source": [
    "## 3) Mixture training: full vs top-50% test-like subset\n",
    "\n",
    "Train a model only on the most test-like rows (by `p_test(train)`) and blend predictions with the full-data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8d9ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_lgb_subset_model(\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    X_test: pd.DataFrame,\n",
    "    p_test_train: np.ndarray,\n",
    "    subset_quantile: float = 0.5,\n",
    "    seed: int = 42,\n",
    "    n_splits: int = 10,\n",
    "    label: str = 'subset',\n",
    "):\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'n_estimators': 12000,\n",
    "        'learning_rate': 0.008,\n",
    "        'num_leaves': 31,\n",
    "        'max_depth': 6,\n",
    "        'min_child_samples': 120,\n",
    "        'feature_fraction': 0.7,\n",
    "        'bagging_fraction': 0.7,\n",
    "        'bagging_freq': 5,\n",
    "        'reg_alpha': 0.8,\n",
    "        'reg_lambda': 1.0,\n",
    "        'random_state': seed,\n",
    "        'verbose': -1,\n",
    "    }\n",
    "\n",
    "    groups = make_shift_groups(p_test_train, n_bins=50)\n",
    "    splitter = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    splits = splitter.split(X, y, groups=groups)\n",
    "\n",
    "    oof = np.zeros(len(X))\n",
    "    test_pred = np.zeros(len(X_test))\n",
    "\n",
    "    q_thr = np.quantile(p_test_train, subset_quantile)\n",
    "    subset_mask = p_test_train >= q_thr\n",
    "    print(f'[{label}] subset_quantile={subset_quantile} -> train rows used ~{subset_mask.mean():.3f}')\n",
    "\n",
    "    for tr, va in splits:\n",
    "        tr_sub = tr[subset_mask[tr]]\n",
    "        if len(tr_sub) < 1000:\n",
    "            tr_sub = tr\n",
    "\n",
    "        m = lgb.LGBMClassifier(**params)\n",
    "        m.fit(\n",
    "            X.iloc[tr_sub], y.iloc[tr_sub],\n",
    "            eval_set=[(X.iloc[va], y.iloc[va])],\n",
    "            callbacks=[lgb.early_stopping(250, verbose=False)]\n",
    "        )\n",
    "        oof[va] = m.predict_proba(X.iloc[va])[:, 1]\n",
    "        test_pred += m.predict_proba(X_test)[:, 1] / n_splits\n",
    "\n",
    "    std_auc = roc_auc_score(y, oof)\n",
    "    w_auc = roc_auc_score(y, oof, sample_weight=density_ratio_weights(p_test_train, clip=(0.2, 5.0)))\n",
    "    print(f'[{label}] CV AUC std: {std_auc:.5f} | weighted: {w_auc:.5f}')\n",
    "    return oof, test_pred\n",
    "\n",
    "oof_v8_sub50, pred_v8_sub50 = cv_lgb_subset_model(\n",
    "    X, y, X_test, p_test_train, subset_quantile=0.50, seed=SEED, n_splits=N_SPLITS, label='V8_SUBSET_TOP50'\n",
    ")\n",
    "pd.DataFrame({'id': test_ids, TARGET: pred_v8_sub50}).to_csv('submission_v8_subset_top50.csv', index=False)\n",
    "print('Saved: submission_v8_subset_top50.csv')\n",
    "\n",
    "pred_v8_mixture_60_40 = pred_v8_base * 0.6 + pred_v8_sub50 * 0.4\n",
    "pd.DataFrame({'id': test_ids, TARGET: pred_v8_mixture_60_40}).to_csv('submission_v8_mixture_60_40.csv', index=False)\n",
    "print('Saved: submission_v8_mixture_60_40.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9978728",
   "metadata": {},
   "source": [
    "## 4) Importance-weighted training\n",
    "\n",
    "Train on all rows with sample weights `w(x) = p/(1-p)` (clipped + normalized)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8e2f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_v8_w, pred_v8_w = cv_lgb_shift_metrics(\n",
    "    X, y, X_test, p_test_train,\n",
    "    sample_weight=w_train, seed=SEED, n_splits=N_SPLITS, use_shift_groups=True,\n",
    "    label='V8_IMPORTANCE_WEIGHTED'\n",
    ")\n",
    "pd.DataFrame({'id': test_ids, TARGET: pred_v8_w}).to_csv('submission_v8_importance_weighted.csv', index=False)\n",
    "print('Saved: submission_v8_importance_weighted.csv')\n",
    "\n",
    "blend_bw = pred_v8_base * 0.6 + pred_v8_w * 0.4\n",
    "pd.DataFrame({'id': test_ids, TARGET: blend_bw}).to_csv('submission_v8_blend_base_weighted_60_40.csv', index=False)\n",
    "print('Saved: submission_v8_blend_base_weighted_60_40.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9098ff6",
   "metadata": {},
   "source": [
    "## 5) Soft de-emphasis of shifted features (quantile binning)\n",
    "\n",
    "We coarsen selected (shift-prone) numeric features by quantile binning.\n",
    "Implementation note: we store bins as integer codes (not Interval categoricals) to avoid LightGBM JSON serialization issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb016458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_bin_joint(\n",
    "    X_train: pd.DataFrame,\n",
    "    X_test: pd.DataFrame,\n",
    "    cols: list[str],\n",
    "    n_bins: int = 50,\n",
    "    drop_original: bool = True,\n",
    "    suffix: str = '__qbin',\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    Xt = X_train.copy()\n",
    "    Xs = X_test.copy()\n",
    "\n",
    "    for c in cols:\n",
    "        if c not in Xt.columns or c not in Xs.columns:\n",
    "            continue\n",
    "        if not pd.api.types.is_numeric_dtype(Xt[c]):\n",
    "            continue\n",
    "\n",
    "        s_all = pd.concat([Xt[c], Xs[c]], axis=0, ignore_index=True)\n",
    "        try:\n",
    "            b_all = pd.qcut(s_all, q=n_bins, duplicates='drop')\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        # Store as stable integer codes (avoids Interval categoricals)\n",
    "        codes = b_all.cat.codes.astype('int16')\n",
    "        Xt[c + suffix] = codes.iloc[: len(Xt)].reset_index(drop=True)\n",
    "        Xs[c + suffix] = codes.iloc[len(Xt):].reset_index(drop=True)\n",
    "\n",
    "        if drop_original:\n",
    "            Xt = Xt.drop(columns=[c])\n",
    "            Xs = Xs.drop(columns=[c])\n",
    "\n",
    "    return Xt, Xs\n",
    "\n",
    "shift_candidates = [\n",
    "    'triglycerides',\n",
    "    'cholesterol_total',\n",
    "    'cholesterol_hdl',\n",
    "    'cholesterol_ldl',\n",
    "    'glucose',\n",
    "    'hba1c',\n",
    "    'insulin',\n",
    "    'bmi',\n",
    "    'waist_circumference',\n",
    "    'hip_circumference',\n",
    "    'waist_hip_ratio',\n",
    "    'systolic_bp',\n",
    "    'diastolic_bp',\n",
    "    'age',\n",
    "    'income',\n",
    "    'education_years',\n",
    "    'physical_activity',\n",
    "    'sleep_hours',\n",
    "    'smoking_pack_years',\n",
    "    'alcohol_units',\n",
    "    'family_history_diabetes',\n",
    "    'diet_score',\n",
    "    'stress_level',\n",
    "    'heart_rate',\n",
    "    'creatinine',\n",
    "    'egfr',\n",
    "    'alt',\n",
    "    'ast',\n",
    "    'crp',\n",
    "]\n",
    "\n",
    "X_soft, X_test_soft = quantile_bin_joint(X, X_test, shift_candidates, n_bins=50, drop_original=True)\n",
    "print('Soft-binned shapes:', X_soft.shape, X_test_soft.shape)\n",
    "\n",
    "oof_v8_soft, pred_v8_soft = cv_lgb_shift_metrics(\n",
    "    X_soft, y, X_test_soft, p_test_train,\n",
    "    sample_weight=None, seed=SEED, n_splits=N_SPLITS, use_shift_groups=True,\n",
    "    label='V8_SOFT_BIN'\n",
    ")\n",
    "pd.DataFrame({'id': test_ids, TARGET: pred_v8_soft}).to_csv('submission_v8_soft_bin.csv', index=False)\n",
    "print('Saved: submission_v8_soft_bin.csv')\n",
    "\n",
    "pred_v8_blend_base_soft = 0.6 * pred_v8_base + 0.4 * pred_v8_soft\n",
    "pd.DataFrame({'id': test_ids, TARGET: pred_v8_blend_base_soft}).to_csv('submission_v8_blend_base_softbin_60_40.csv', index=False)\n",
    "print('Saved: submission_v8_blend_base_softbin_60_40.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4896ae76",
   "metadata": {},
   "source": [
    "## 6) Gated blend on test (row-wise mixture)\n",
    "\n",
    "Blend base vs subset predictions with a gate `α(x)` based on `p_test(test)` (more test-like → more weight on subset model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4868cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Gate centered at test q70 (reasonable default)\n",
    "q50, q70, q85 = np.quantile(p_test_test, [0.5, 0.7, 0.85])\n",
    "print('p_test(test) q50/q70/q85:', (q50, q70, q85))\n",
    "\n",
    "t0 = float(q70)\n",
    "temp = 0.06\n",
    "alpha = sigmoid((p_test_test - t0) / temp)\n",
    "pred_v8_gated = (1 - alpha) * pred_v8_base + alpha * pred_v8_sub50\n",
    "pd.DataFrame({'id': test_ids, TARGET: pred_v8_gated}).to_csv('submission_v8_gated_base_sub50_sigmoid.csv', index=False)\n",
    "print('Saved: submission_v8_gated_base_sub50_sigmoid.csv')\n",
    "\n",
    "temp2 = 0.04\n",
    "alpha2 = sigmoid((p_test_test - t0) / temp2)\n",
    "pred_v8_gated2 = (1 - alpha2) * pred_v8_base + alpha2 * pred_v8_sub50\n",
    "pd.DataFrame({'id': test_ids, TARGET: pred_v8_gated2}).to_csv('submission_v8_gated_base_sub50_sigmoid_sharp.csv', index=False)\n",
    "print('Saved: submission_v8_gated_base_sub50_sigmoid_sharp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f06face7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (700000, 26)\n",
      "Test shape : (300000, 25)\n",
      "Target rate: 0.6232957142857143\n",
      "Categorical cols: ['gender', 'ethnicity', 'education_level', 'income_level', 'smoking_status', 'employment_status']\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "print('Train shape:', train.shape)\n",
    "print('Test shape :', test.shape)\n",
    "print('Target rate:', train[TARGET].mean())\n",
    "\n",
    "test_ids = test['id']\n",
    "train = train.drop(columns=['id'])\n",
    "test = test.drop(columns=['id'])\n",
    "\n",
    "def to_category(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    for c in out.columns:\n",
    "        if out[c].dtype == 'object':\n",
    "            out[c] = out[c].astype('category')\n",
    "    return out\n",
    "\n",
    "train = to_category(train)\n",
    "test = to_category(test)\n",
    "\n",
    "y = train[TARGET].astype(int)\n",
    "X = train.drop(columns=[TARGET])\n",
    "X_test = test.copy()\n",
    "\n",
    "cat_cols = X.select_dtypes(include=['category']).columns.tolist()\n",
    "print('Categorical cols:', cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31552a7a",
   "metadata": {},
   "source": [
    "## 1) Shift-aware evaluation: adversarial test-likeness score\n",
    "\n",
    "We train a domain classifier to predict `is_test` using features only, then use:\n",
    "- `p_test(x)` as a *test-likeness* score\n",
    "- density-ratio weights $w(x) pprox \frac{p_{test}(x)}{p_{train}(x)} = \frac{p}{1-p}$\n",
    "- shift-aware fold grouping via quantile bins of `p_test(x)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3c457e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain (train vs test) CV AUC: 0.64956\n",
      "p_test(train) summary: [0.08491359 0.19052777 0.24689076 0.37697885 0.95289083]\n",
      "p_test(test)  summary: [0.1139838  0.22369724 0.32782366 0.59714959 0.98700743]\n"
     ]
    }
   ],
   "source": [
    "def fit_domain_classifier_get_p_test(X_train: pd.DataFrame, X_test: pd.DataFrame, seed: int = 42):\n",
    "    X_all = pd.concat([X_train, X_test], axis=0, ignore_index=True)\n",
    "    y_dom = np.concatenate([np.zeros(len(X_train), dtype=int), np.ones(len(X_test), dtype=int)])\n",
    "\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'n_estimators': 4000,\n",
    "        'learning_rate': 0.02,\n",
    "        'num_leaves': 63,\n",
    "        'max_depth': -1,\n",
    "        'min_child_samples': 100,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 1,\n",
    "        'reg_alpha': 0.0,\n",
    "        'reg_lambda': 1.0,\n",
    "        'random_state': seed,\n",
    "        'verbose': -1,\n",
    "    }\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    oof = np.zeros(len(X_all))\n",
    "    for tr, va in kf.split(X_all, y_dom):\n",
    "        m = lgb.LGBMClassifier(**params)\n",
    "        m.fit(\n",
    "            X_all.iloc[tr], y_dom[tr],\n",
    "            eval_set=[(X_all.iloc[va], y_dom[va])],\n",
    "            callbacks=[lgb.early_stopping(100, verbose=False)]\n",
    "        )\n",
    "        oof[va] = m.predict_proba(X_all.iloc[va])[:, 1]\n",
    "    dom_auc = roc_auc_score(y_dom, oof)\n",
    "    print(f'Domain (train vs test) CV AUC: {dom_auc:.5f}')\n",
    "\n",
    "    # Fit final model on all data to score train/test consistently\n",
    "    final = lgb.LGBMClassifier(**params)\n",
    "    final.fit(X_all, y_dom)\n",
    "    p_all = final.predict_proba(X_all)[:, 1]\n",
    "    p_train = p_all[: len(X_train)]\n",
    "    p_test = p_all[len(X_train) :]\n",
    "    return p_train, p_test, dom_auc\n",
    "\n",
    "p_test_train, p_test_test, dom_auc = fit_domain_classifier_get_p_test(X, X_test, seed=SEED)\n",
    "print('p_test(train) summary:', np.quantile(p_test_train, [0, 0.1, 0.5, 0.9, 1]))\n",
    "print('p_test(test)  summary:', np.quantile(p_test_test, [0, 0.1, 0.5, 0.9, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f17d756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights summary: [ 0.50547551  0.594876    0.82854668  1.52927051 12.63688783]\n"
     ]
    }
   ],
   "source": [
    "def density_ratio_weights(p: np.ndarray, clip=(0.2, 5.0)):\n",
    "    eps = 1e-6\n",
    "    p = np.clip(p, eps, 1 - eps)\n",
    "    w = p / (1 - p)\n",
    "    w = np.clip(w, clip[0], clip[1])\n",
    "    # normalize mean weight to 1\n",
    "    w = w / np.mean(w)\n",
    "    return w\n",
    "\n",
    "w_train = density_ratio_weights(p_test_train, clip=(0.2, 5.0))\n",
    "print('weights summary:', np.quantile(w_train, [0, 0.1, 0.5, 0.9, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ae6028b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique shift groups: 50\n"
     ]
    }
   ],
   "source": [
    "def make_shift_groups(p_test: np.ndarray, n_bins: int = 50):\n",
    "    # quantile bins (groups) for StratifiedGroupKFold\n",
    "    qs = np.quantile(p_test, np.linspace(0, 1, n_bins + 1))\n",
    "    # guard duplicates\n",
    "    qs = np.unique(qs)\n",
    "    # if too many duplicates, fall back\n",
    "    if len(qs) <= 2:\n",
    "        return np.zeros_like(p_test, dtype=int)\n",
    "    groups = np.digitize(p_test, qs[1:-1], right=True)\n",
    "    return groups\n",
    "\n",
    "shift_groups = make_shift_groups(p_test_train, n_bins=50)\n",
    "print('unique shift groups:', len(np.unique(shift_groups)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68579fa",
   "metadata": {},
   "source": [
    "### Shift-aware CV metrics\n",
    "\n",
    "We report:\n",
    "- Standard AUC\n",
    "- Weighted AUC using density-ratio weights (proxy for test risk)\n",
    "- AUC on the most test-like slice of each validation fold (top 30% by `p_test`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4381e5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V8_BASE_SHIFT_CV] CV AUC std: 0.72897 | weighted: 0.73988 | val-top30%: 0.74692\n",
      "Saved: submission_v8_base_shiftcv.csv\n"
     ]
    }
   ],
   "source": [
    "def weighted_auc(y_true, y_score, sample_weight):\n",
    "    # sklearn roc_auc_score supports sample_weight\n",
    "    return roc_auc_score(y_true, y_score, sample_weight=sample_weight)\n",
    "\n",
    "def cv_lgb_shift_metrics(\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    X_test: pd.DataFrame,\n",
    "    p_test_train: np.ndarray,\n",
    "    sample_weight: np.ndarray | None = None,\n",
    "    seed: int = 42,\n",
    "    n_splits: int = 10,\n",
    "    use_shift_groups: bool = True,\n",
    "    label: str = 'model',\n",
    "):\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'n_estimators': 8000,\n",
    "        'learning_rate': 0.01,\n",
    "        'num_leaves': 31,\n",
    "        'max_depth': 6,\n",
    "        'min_child_samples': 80,\n",
    "        'feature_fraction': 0.7,\n",
    "        'bagging_fraction': 0.7,\n",
    "        'bagging_freq': 5,\n",
    "        'reg_alpha': 0.5,\n",
    "        'reg_lambda': 0.5,\n",
    "        'random_state': seed,\n",
    "        'verbose': -1,\n",
    "    }\n",
    "\n",
    "    if use_shift_groups:\n",
    "        groups = make_shift_groups(p_test_train, n_bins=50)\n",
    "        splitter = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "        splits = splitter.split(X, y, groups=groups)\n",
    "    else:\n",
    "        splitter = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "        splits = splitter.split(X, y)\n",
    "\n",
    "    oof = np.zeros(len(X))\n",
    "    test_pred = np.zeros(len(X_test))\n",
    "    fold_std = []\n",
    "    fold_w = []\n",
    "    fold_top = []\n",
    "\n",
    "    w_proxy = density_ratio_weights(p_test_train, clip=(0.2, 5.0))\n",
    "\n",
    "    for fold, (tr, va) in enumerate(splits):\n",
    "        X_tr, X_va = X.iloc[tr], X.iloc[va]\n",
    "        y_tr, y_va = y.iloc[tr], y.iloc[va]\n",
    "\n",
    "        fit_w = sample_weight[tr] if sample_weight is not None else None\n",
    "\n",
    "        m = lgb.LGBMClassifier(**params)\n",
    "        m.fit(\n",
    "            X_tr, y_tr,\n",
    "            sample_weight=fit_w,\n",
    "            eval_set=[(X_va, y_va)],\n",
    "            callbacks=[lgb.early_stopping(200, verbose=False)]\n",
    "        )\n",
    "        p_va = m.predict_proba(X_va)[:, 1]\n",
    "        oof[va] = p_va\n",
    "        test_pred += m.predict_proba(X_test)[:, 1] / n_splits\n",
    "\n",
    "        auc_std = roc_auc_score(y_va, p_va)\n",
    "        auc_w = weighted_auc(y_va, p_va, w_proxy[va])\n",
    "        # top test-like slice within validation\n",
    "        thr = np.quantile(p_test_train[va], 0.70)\n",
    "        idx_top = va[p_test_train[va] >= thr]\n",
    "        if len(idx_top) > 50:\n",
    "            auc_top = roc_auc_score(y.iloc[idx_top], oof[idx_top])\n",
    "        else:\n",
    "            auc_top = np.nan\n",
    "\n",
    "        fold_std.append(auc_std)\n",
    "        fold_w.append(auc_w)\n",
    "        fold_top.append(auc_top)\n",
    "\n",
    "    overall_std = roc_auc_score(y, oof)\n",
    "    overall_w = weighted_auc(y, oof, w_proxy)\n",
    "    overall_top = np.nanmean(fold_top)\n",
    "\n",
    "    print(f'[{label}] CV AUC std: {overall_std:.5f} | weighted: {overall_w:.5f} | val-top30%: {overall_top:.5f}')\n",
    "    return oof, test_pred, {'std': overall_std, 'weighted': overall_w, 'top30': overall_top}\n",
    "\n",
    "# Baseline shift-aware evaluation (no special weights, shift-group folds)\n",
    "oof_v8_base, pred_v8_base, m_v8_base = cv_lgb_shift_metrics(\n",
    "    X, y, X_test, p_test_train, sample_weight=None, seed=SEED, n_splits=N_SPLITS, use_shift_groups=True, label='V8_BASE_SHIFT_CV'\n",
    ")\n",
    "pd.DataFrame({'id': test_ids, TARGET: pred_v8_base}).to_csv('submission_v8_base_shiftcv.csv', index=False)\n",
    "print('Saved: submission_v8_base_shiftcv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b463197",
   "metadata": {},
   "source": [
    "## 2) Mixture training: full-train + test-like subset + blend\n",
    "\n",
    "We train:\n",
    "- Model A: on all training rows\n",
    "- Model B: on top-X% most test-like training rows (by `p_test(train)`)\n",
    "Then blend predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a0279bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V8_SUBSET_TOP50] subset_quantile=0.5 -> train rows used ~0.500\n",
      "[V8_SUBSET_TOP50] CV AUC std: 0.72665 | weighted: 0.73815\n",
      "Saved: submission_v8_subset_top50.csv\n",
      "Saved: submission_v8_mixture_60_40.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Mixture training (full-train + test-like subset)\n",
    "def cv_lgb_subset_model(\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    X_test: pd.DataFrame,\n",
    "    p_test_train: np.ndarray,\n",
    "    subset_quantile: float = 0.5,\n",
    "    seed: int = 42,\n",
    "    n_splits: int = 10,\n",
    "    label: str = 'subset',\n",
    "):\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'n_estimators': 12000,\n",
    "        'learning_rate': 0.008,\n",
    "        'num_leaves': 31,\n",
    "        'max_depth': 6,\n",
    "        'min_child_samples': 120,\n",
    "        'feature_fraction': 0.7,\n",
    "        'bagging_fraction': 0.7,\n",
    "        'bagging_freq': 5,\n",
    "        'reg_alpha': 0.8,\n",
    "        'reg_lambda': 1.0,\n",
    "        'random_state': seed,\n",
    "        'verbose': -1,\n",
    "    }\n",
    "\n",
    "    groups = make_shift_groups(p_test_train, n_bins=50)\n",
    "    splitter = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    splits = splitter.split(X, y, groups=groups)\n",
    "\n",
    "    oof = np.zeros(len(X))\n",
    "    test_pred = np.zeros(len(X_test))\n",
    "\n",
    "    q_thr = np.quantile(p_test_train, subset_quantile)\n",
    "    subset_mask = p_test_train >= q_thr\n",
    "    print(f'[{label}] subset_quantile={subset_quantile} -> train rows used ~{subset_mask.mean():.3f}')\n",
    "\n",
    "    for fold, (tr, va) in enumerate(splits):\n",
    "        tr_sub = tr[subset_mask[tr]]\n",
    "        if len(tr_sub) < 1000:\n",
    "            tr_sub = tr  # fallback\n",
    "\n",
    "        m = lgb.LGBMClassifier(**params)\n",
    "        m.fit(\n",
    "            X.iloc[tr_sub], y.iloc[tr_sub],\n",
    "            eval_set=[(X.iloc[va], y.iloc[va])],\n",
    "            callbacks=[lgb.early_stopping(250, verbose=False)]\n",
    "        )\n",
    "        oof[va] = m.predict_proba(X.iloc[va])[:, 1]\n",
    "        test_pred += m.predict_proba(X_test)[:, 1] / n_splits\n",
    "\n",
    "    std_auc = roc_auc_score(y, oof)\n",
    "    w_auc = roc_auc_score(y, oof, sample_weight=density_ratio_weights(p_test_train, clip=(0.2, 5.0)))\n",
    "    print(f'[{label}] CV AUC std: {std_auc:.5f} | weighted: {w_auc:.5f}')\n",
    "    return oof, test_pred, {'std': std_auc, 'weighted': w_auc}\n",
    "\n",
    "oof_v8_sub50, pred_v8_sub50, m_v8_sub50 = cv_lgb_subset_model(\n",
    "    X, y, X_test, p_test_train, subset_quantile=0.50, seed=SEED, n_splits=N_SPLITS, label='V8_SUBSET_TOP50'\n",
    ")\n",
    "pd.DataFrame({'id': test_ids, TARGET: pred_v8_sub50}).to_csv('submission_v8_subset_top50.csv', index=False)\n",
    "print('Saved: submission_v8_subset_top50.csv')\n",
    "\n",
    "# Simple global blend with base shift-aware model\n",
    "pred_v8_mixture_60_40 = pred_v8_base * 0.6 + pred_v8_sub50 * 0.4\n",
    "pd.DataFrame({'id': test_ids, TARGET: pred_v8_mixture_60_40}).to_csv('submission_v8_mixture_60_40.csv', index=False)\n",
    "print('Saved: submission_v8_mixture_60_40.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f4c501",
   "metadata": {},
   "source": [
    "## 3) Importance-weighted training (density ratio weights)\n",
    "\n",
    "Train a model on all rows but weight examples by clipped density ratio $w(x)=\frac{p}{1-p}$ where $p=p(istest=1|x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00effffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V8_IMPORTANCE_WEIGHTED] CV AUC std: 0.72811 | weighted: 0.73929 | val-top30%: 0.74641\n",
      "Saved: submission_v8_importance_weighted.csv\n",
      "Saved: submission_v8_blend_base_weighted_60_40.csv\n"
     ]
    }
   ],
   "source": [
    "# Importance-weighted model\n",
    "oof_v8_w, pred_v8_w, m_v8_w = cv_lgb_shift_metrics(\n",
    "    X, y, X_test, p_test_train, sample_weight=w_train, seed=SEED, n_splits=N_SPLITS, use_shift_groups=True, label='V8_IMPORTANCE_WEIGHTED'\n",
    ")\n",
    "pd.DataFrame({'id': test_ids, TARGET: pred_v8_w}).to_csv('submission_v8_importance_weighted.csv', index=False)\n",
    "print('Saved: submission_v8_importance_weighted.csv')\n",
    "\n",
    "# Blend base and weighted\n",
    "blend_bw = pred_v8_base * 0.6 + pred_v8_w * 0.4\n",
    "pd.DataFrame({'id': test_ids, TARGET: blend_bw}).to_csv('submission_v8_blend_base_weighted_60_40.csv', index=False)\n",
    "print('Saved: submission_v8_blend_base_weighted_60_40.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15db8783",
   "metadata": {},
   "source": [
    "## 4) Soft de-emphasis of shifted features (quantile binning)\n",
    "\n",
    "Instead of dropping shifted features (which hurt CV), we *coarsen* them by quantile-binning to reduce over-sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1341095a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3936525092.py, line 18)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m'cholesterol_total',\u001b[39m\n                        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m incomplete input\n"
     ]
    }
   ],
   "source": [
    "def quantile_bin_columns(df: pd.DataFrame, cols: list[str], n_bins: int = 50) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    for c in cols:\n",
    "        if c not in out.columns:\n",
    "            continue\n",
    "        if pd.api.types.is_numeric_dtype(out[c]):\n",
    "            # qcut to category bins\n",
    "            try:\n",
    "                binned = pd.qcut(out[c], q=n_bins, duplicates='drop')\n",
    "                out[c + '__qbin'] = binned.astype('category')\n",
    "            except Exception:\n",
    "                pass\n",
    "    return out\n",
    "\n",
    "# Candidate shifted features from prior analysis (keep only if present)\n",
    "shift_candidates = [\n",
    "    'triglycerides',\n",
    "    'cholesterol_total',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91323816",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
