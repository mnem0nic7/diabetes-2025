{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81b14f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "N_SPLITS = 10  # Use 10 folds like top solutions\n",
    "TARGET = 'diagnosed_diabetes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b8f769e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (700000, 26)\n",
      "Test shape: (300000, 25)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "\n",
    "test_ids = test['id']\n",
    "train = train.drop(columns=['id'])\n",
    "test = test.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba2c58a",
   "metadata": {},
   "source": [
    "## Part 1: Adversarial Validation\n",
    "Check if train and test distributions are similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a2e7d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running adversarial validation...\n",
      "\n",
      "Adversarial AUC: 0.63259\n",
      "(Close to 0.5 = train/test are similar, >> 0.5 = distribution shift)\n"
     ]
    }
   ],
   "source": [
    "# Adversarial validation to check train-test similarity\n",
    "def run_adversarial_validation(train_df, test_df, target_col):\n",
    "    \"\"\"Train a model to distinguish train from test data.\n",
    "    AUC close to 0.5 = similar distributions (good)\n",
    "    AUC >> 0.5 = different distributions (may need domain adaptation)\n",
    "    \"\"\"\n",
    "    # Prepare features\n",
    "    X_train = train_df.drop(columns=[target_col])\n",
    "    X_test = test_df.copy()\n",
    "    \n",
    "    # Convert categoricals\n",
    "    cat_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "    for col in cat_cols:\n",
    "        combined = pd.concat([X_train[col], X_test[col]], axis=0)\n",
    "        categories = pd.Categorical(combined).categories\n",
    "        X_train[col] = pd.Categorical(X_train[col], categories=categories)\n",
    "        X_test[col] = pd.Categorical(X_test[col], categories=categories)\n",
    "    \n",
    "    # Create domain labels: 0=train, 1=test\n",
    "    X_all = pd.concat([X_train, X_test], axis=0, ignore_index=True)\n",
    "    y_domain = np.concatenate([np.zeros(len(X_train)), np.ones(len(X_test))])\n",
    "    \n",
    "    # Train adversarial model\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    oof_preds = np.zeros(len(X_all))\n",
    "    \n",
    "    print(\"Running adversarial validation...\")\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_all, y_domain)):\n",
    "        X_tr, X_val = X_all.iloc[train_idx], X_all.iloc[val_idx]\n",
    "        y_tr, y_val = y_domain[train_idx], y_domain[val_idx]\n",
    "        \n",
    "        model = lgb.LGBMClassifier(\n",
    "            n_estimators=500,\n",
    "            learning_rate=0.05,\n",
    "            num_leaves=31,\n",
    "            random_state=SEED,\n",
    "            verbose=-1\n",
    "        )\n",
    "        model.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            callbacks=[lgb.early_stopping(50, verbose=False)]\n",
    "        )\n",
    "        oof_preds[val_idx] = model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    adv_auc = roc_auc_score(y_domain, oof_preds)\n",
    "    print(f\"\\nAdversarial AUC: {adv_auc:.5f}\")\n",
    "    print(\"(Close to 0.5 = train/test are similar, >> 0.5 = distribution shift)\")\n",
    "    \n",
    "    # Return train sample weights (higher weight for samples that look more like test)\n",
    "    train_probs = oof_preds[:len(X_train)]\n",
    "    weights = (train_probs + 1e-6) / (1 - train_probs + 1e-6)\n",
    "    weights = np.clip(weights, np.percentile(weights, 1), np.percentile(weights, 99))\n",
    "    weights = weights / weights.mean()\n",
    "    \n",
    "    return adv_auc, weights\n",
    "\n",
    "adv_auc, sample_weights = run_adversarial_validation(train, test, TARGET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc44fbd",
   "metadata": {},
   "source": [
    "## Part 2: Data Preparation (Minimal - Following Top Solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32cd4ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types (simple):\n",
      "age                                      int64\n",
      "alcohol_consumption_per_week             int64\n",
      "physical_activity_minutes_per_week       int64\n",
      "diet_score                             float64\n",
      "sleep_hours_per_day                    float64\n",
      "screen_time_hours_per_day              float64\n",
      "bmi                                    float64\n",
      "waist_to_hip_ratio                     float64\n",
      "systolic_bp                              int64\n",
      "diastolic_bp                             int64\n",
      "heart_rate                               int64\n",
      "cholesterol_total                        int64\n",
      "hdl_cholesterol                          int64\n",
      "ldl_cholesterol                          int64\n",
      "triglycerides                            int64\n",
      "gender                                category\n",
      "ethnicity                             category\n",
      "education_level                       category\n",
      "income_level                          category\n",
      "smoking_status                        category\n",
      "employment_status                     category\n",
      "family_history_diabetes                  int64\n",
      "hypertension_history                     int64\n",
      "cardiovascular_history                   int64\n",
      "diagnosed_diabetes                     float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Simple categorical encoding - let the models handle it natively\n",
    "def prepare_data_simple(df):\n",
    "    \"\"\"Minimal preprocessing - convert object cols to category dtype\"\"\"\n",
    "    df = df.copy()\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].astype('category')\n",
    "    return df\n",
    "\n",
    "# Simple ordinal mapping (from top-34 solution)\n",
    "def prepare_data_mapped(df):\n",
    "    \"\"\"Map categoricals to ordinals for XGBoost\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ordinal mappings\n",
    "    smoke_map = {'Never': 0, 'Former': 1, 'Current': 2}\n",
    "    gender_map = {'Female': 0, 'Male': 1}\n",
    "    \n",
    "    if 'smoking_status' in df.columns:\n",
    "        df['smoking_status'] = df['smoking_status'].map(smoke_map).fillna(0)\n",
    "    if 'gender' in df.columns:\n",
    "        df['gender'] = df['gender'].map(gender_map).fillna(0)\n",
    "    \n",
    "    # Cast boolean columns to int\n",
    "    bool_cols = ['family_history_diabetes', 'hypertension_history', 'cardiovascular_history']\n",
    "    for col in bool_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Prepare different versions\n",
    "train_simple = prepare_data_simple(train.copy())\n",
    "test_simple = prepare_data_simple(test.copy())\n",
    "\n",
    "print(\"Data types (simple):\")\n",
    "print(train_simple.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d158837c",
   "metadata": {},
   "source": [
    "## Part 3: Minimal Feature Engineering (Only Proven Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba5c9deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features after minimal FE: 30\n"
     ]
    }
   ],
   "source": [
    "def add_minimal_features(df):\n",
    "    \"\"\"Add only the most robust features from top solutions\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # From top-34 solution - cardiovascular indicators\n",
    "    df['MAP'] = (df['systolic_bp'] + 2 * df['diastolic_bp']) / 3\n",
    "    df['Pulse_Pressure'] = df['systolic_bp'] - df['diastolic_bp']\n",
    "    \n",
    "    # Lipid ratios (clinically validated)\n",
    "    df['Total_HDL_Ratio'] = df['cholesterol_total'] / (df['hdl_cholesterol'] + 1e-5)\n",
    "    df['TG_HDL_Ratio'] = df['triglycerides'] / (df['hdl_cholesterol'] + 1e-5)\n",
    "    \n",
    "    # Metabolic syndrome index\n",
    "    df['Metabolic_Index'] = df['bmi'] * df['waist_to_hip_ratio']\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_fe = add_minimal_features(train_simple.copy())\n",
    "test_fe = add_minimal_features(test_simple.copy())\n",
    "\n",
    "print(f\"Features after minimal FE: {train_fe.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb043a6d",
   "metadata": {},
   "source": [
    "## Part 4: Model Training - Simple Baseline (No FE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bf2e6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training WITHOUT feature engineering (like AbyssSkb) ===\n",
      "Training LightGBM Simple (10-fold)...\n",
      "  Fold 1 AUC: 0.72824\n",
      "  Fold 2 AUC: 0.72937\n",
      "  Fold 3 AUC: 0.72719\n",
      "  Fold 4 AUC: 0.72729\n",
      "  Fold 5 AUC: 0.72845\n",
      "  Fold 6 AUC: 0.72873\n",
      "  Fold 7 AUC: 0.72697\n",
      "  Fold 8 AUC: 0.73115\n",
      "  Fold 9 AUC: 0.73044\n",
      "  Fold 10 AUC: 0.72751\n",
      "Overall OOF AUC: 0.72853\n"
     ]
    }
   ],
   "source": [
    "def train_lgb_simple(X, y, X_test, n_splits=10, use_weights=False, weights=None):\n",
    "    \"\"\"Train LightGBM with native categorical handling (like AbyssSkb)\"\"\"\n",
    "    \n",
    "    cat_cols = X.select_dtypes(include=['category']).columns.tolist()\n",
    "    \n",
    "    # Very conservative parameters\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'n_estimators': 5000,\n",
    "        'learning_rate': 0.01,\n",
    "        'num_leaves': 31,\n",
    "        'max_depth': 6,\n",
    "        'min_child_samples': 50,\n",
    "        'feature_fraction': 0.7,\n",
    "        'bagging_fraction': 0.7,\n",
    "        'bagging_freq': 5,\n",
    "        'reg_alpha': 0.5,\n",
    "        'reg_lambda': 0.5,\n",
    "        'random_state': SEED,\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "    oof_preds = np.zeros(len(X))\n",
    "    test_preds = np.zeros(len(X_test))\n",
    "    \n",
    "    print(f\"Training LightGBM Simple ({n_splits}-fold)...\")\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        sample_weight = weights[train_idx] if use_weights and weights is not None else None\n",
    "        \n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            callbacks=[lgb.early_stopping(100, verbose=False)],\n",
    "            sample_weight=sample_weight\n",
    "        )\n",
    "        \n",
    "        oof_preds[val_idx] = model.predict_proba(X_val)[:, 1]\n",
    "        test_preds += model.predict_proba(X_test)[:, 1] / n_splits\n",
    "        \n",
    "        fold_auc = roc_auc_score(y_val, oof_preds[val_idx])\n",
    "        print(f\"  Fold {fold+1} AUC: {fold_auc:.5f}\")\n",
    "    \n",
    "    oof_auc = roc_auc_score(y, oof_preds)\n",
    "    print(f\"Overall OOF AUC: {oof_auc:.5f}\")\n",
    "    \n",
    "    return oof_preds, test_preds, oof_auc\n",
    "\n",
    "# Train on simple data (no FE)\n",
    "y = train_simple[TARGET]\n",
    "X_simple = train_simple.drop(columns=[TARGET])\n",
    "X_test_simple = test_simple.copy()\n",
    "\n",
    "print(\"\\n=== Training WITHOUT feature engineering (like AbyssSkb) ===\")\n",
    "oof_lgb_simple, test_lgb_simple, auc_lgb_simple = train_lgb_simple(\n",
    "    X_simple, y, X_test_simple, n_splits=N_SPLITS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222e07d7",
   "metadata": {},
   "source": [
    "## Part 5: Model Training - With Minimal FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3785b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training WITH minimal feature engineering ===\n",
      "Training LightGBM Simple (10-fold)...\n",
      "  Fold 1 AUC: 0.72782\n",
      "  Fold 1 AUC: 0.72782\n",
      "  Fold 2 AUC: 0.72888\n",
      "  Fold 2 AUC: 0.72888\n",
      "  Fold 3 AUC: 0.72706\n",
      "  Fold 3 AUC: 0.72706\n",
      "  Fold 4 AUC: 0.72674\n",
      "  Fold 4 AUC: 0.72674\n",
      "  Fold 5 AUC: 0.72773\n",
      "  Fold 5 AUC: 0.72773\n",
      "  Fold 6 AUC: 0.72822\n",
      "  Fold 6 AUC: 0.72822\n",
      "  Fold 7 AUC: 0.72650\n",
      "  Fold 7 AUC: 0.72650\n",
      "  Fold 8 AUC: 0.73091\n",
      "  Fold 8 AUC: 0.73091\n",
      "  Fold 9 AUC: 0.73012\n",
      "  Fold 9 AUC: 0.73012\n",
      "  Fold 10 AUC: 0.72671\n",
      "Overall OOF AUC: 0.72807\n",
      "  Fold 10 AUC: 0.72671\n",
      "Overall OOF AUC: 0.72807\n"
     ]
    }
   ],
   "source": [
    "# Train on data with minimal FE\n",
    "X_fe = train_fe.drop(columns=[TARGET])\n",
    "X_test_fe = test_fe.copy()\n",
    "\n",
    "print(\"\\n=== Training WITH minimal feature engineering ===\")\n",
    "oof_lgb_fe, test_lgb_fe, auc_lgb_fe = train_lgb_simple(\n",
    "    X_fe, y, X_test_fe, n_splits=N_SPLITS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd2f736",
   "metadata": {},
   "source": [
    "## Part 6: CatBoost Model (From Top-34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c503e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training CatBoost (simple data) ===\n",
      "Training CatBoost (10-fold)...\n",
      "  Fold 1 AUC: 0.72109\n",
      "  Fold 1 AUC: 0.72109\n",
      "  Fold 2 AUC: 0.72197\n",
      "  Fold 2 AUC: 0.72197\n",
      "  Fold 3 AUC: 0.72000\n",
      "  Fold 3 AUC: 0.72000\n",
      "  Fold 4 AUC: 0.71904\n",
      "  Fold 4 AUC: 0.71904\n",
      "  Fold 5 AUC: 0.72112\n",
      "  Fold 5 AUC: 0.72112\n",
      "  Fold 6 AUC: 0.72044\n",
      "  Fold 6 AUC: 0.72044\n",
      "  Fold 7 AUC: 0.71949\n",
      "  Fold 7 AUC: 0.71949\n",
      "  Fold 8 AUC: 0.72358\n",
      "  Fold 8 AUC: 0.72358\n",
      "  Fold 9 AUC: 0.72321\n",
      "  Fold 9 AUC: 0.72321\n",
      "  Fold 10 AUC: 0.71946\n",
      "  Fold 10 AUC: 0.71946\n",
      "Overall OOF AUC: 0.72093\n",
      "Overall OOF AUC: 0.72093\n"
     ]
    }
   ],
   "source": [
    "def train_catboost(X, y, X_test, n_splits=10):\n",
    "    \"\"\"Train CatBoost with native categorical handling\"\"\"\n",
    "    \n",
    "    cat_cols = X.select_dtypes(include=['category', 'object']).columns.tolist()\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "    oof_preds = np.zeros(len(X))\n",
    "    test_preds = np.zeros(len(X_test))\n",
    "    \n",
    "    print(f\"Training CatBoost ({n_splits}-fold)...\")\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        model = cb.CatBoostClassifier(\n",
    "            iterations=3000,\n",
    "            learning_rate=0.01,\n",
    "            depth=5,\n",
    "            l2_leaf_reg=5,\n",
    "            random_seed=SEED + fold,\n",
    "            verbose=False,\n",
    "            early_stopping_rounds=200\n",
    "        )\n",
    "        \n",
    "        model.fit(\n",
    "            X_tr, y_tr,\n",
    "            cat_features=cat_cols,\n",
    "            eval_set=(X_val, y_val)\n",
    "        )\n",
    "        \n",
    "        oof_preds[val_idx] = model.predict_proba(X_val)[:, 1]\n",
    "        test_preds += model.predict_proba(X_test)[:, 1] / n_splits\n",
    "        \n",
    "        fold_auc = roc_auc_score(y_val, oof_preds[val_idx])\n",
    "        print(f\"  Fold {fold+1} AUC: {fold_auc:.5f}\")\n",
    "    \n",
    "    oof_auc = roc_auc_score(y, oof_preds)\n",
    "    print(f\"Overall OOF AUC: {oof_auc:.5f}\")\n",
    "    \n",
    "    return oof_preds, test_preds, oof_auc\n",
    "\n",
    "print(\"\\n=== Training CatBoost (simple data) ===\")\n",
    "oof_cat_simple, test_cat_simple, auc_cat_simple = train_catboost(\n",
    "    X_simple, y, X_test_simple, n_splits=N_SPLITS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccbd566",
   "metadata": {},
   "source": [
    "## Part 7: XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfe7ec90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training XGBoost (simple data) ===\n",
      "Training XGBoost (10-fold)...\n",
      "Training XGBoost (10-fold)...\n",
      "  Fold 1 AUC: 0.72508\n",
      "  Fold 1 AUC: 0.72508\n",
      "  Fold 2 AUC: 0.72704\n",
      "  Fold 2 AUC: 0.72704\n",
      "  Fold 3 AUC: 0.72381\n",
      "  Fold 3 AUC: 0.72381\n",
      "  Fold 4 AUC: 0.72370\n",
      "  Fold 4 AUC: 0.72370\n",
      "  Fold 5 AUC: 0.72510\n",
      "  Fold 5 AUC: 0.72510\n",
      "  Fold 6 AUC: 0.72488\n",
      "  Fold 6 AUC: 0.72488\n",
      "  Fold 7 AUC: 0.72377\n",
      "  Fold 7 AUC: 0.72377\n",
      "  Fold 8 AUC: 0.72843\n",
      "  Fold 8 AUC: 0.72843\n",
      "  Fold 9 AUC: 0.72747\n",
      "  Fold 9 AUC: 0.72747\n",
      "  Fold 10 AUC: 0.72421\n",
      "Overall OOF AUC: 0.72534\n",
      "  Fold 10 AUC: 0.72421\n",
      "Overall OOF AUC: 0.72534\n"
     ]
    }
   ],
   "source": [
    "def train_xgboost(X, y, X_test, n_splits=10):\n",
    "    \"\"\"Train XGBoost (requires numeric encoding)\"\"\"\n",
    "    \n",
    "    # Convert categories to codes for XGBoost\n",
    "    X_enc = X.copy()\n",
    "    X_test_enc = X_test.copy()\n",
    "    \n",
    "    for col in X_enc.select_dtypes(include=['category']).columns:\n",
    "        X_enc[col] = X_enc[col].cat.codes\n",
    "        X_test_enc[col] = X_test_enc[col].cat.codes\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "    oof_preds = np.zeros(len(X))\n",
    "    test_preds = np.zeros(len(X_test))\n",
    "    \n",
    "    print(f\"Training XGBoost ({n_splits}-fold)...\")\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_enc, y)):\n",
    "        X_tr, X_val = X_enc.iloc[train_idx], X_enc.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        model = xgb.XGBClassifier(\n",
    "            n_estimators=3000,\n",
    "            learning_rate=0.01,\n",
    "            max_depth=5,\n",
    "            subsample=0.7,\n",
    "            colsample_bytree=0.5,\n",
    "            reg_lambda=2.0,\n",
    "            reg_alpha=0.5,\n",
    "            random_state=SEED + fold,\n",
    "            tree_method='hist',\n",
    "            early_stopping_rounds=200\n",
    "        )\n",
    "        \n",
    "        model.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        oof_preds[val_idx] = model.predict_proba(X_val)[:, 1]\n",
    "        test_preds += model.predict_proba(X_test_enc)[:, 1] / n_splits\n",
    "        \n",
    "        fold_auc = roc_auc_score(y_val, oof_preds[val_idx])\n",
    "        print(f\"  Fold {fold+1} AUC: {fold_auc:.5f}\")\n",
    "    \n",
    "    oof_auc = roc_auc_score(y, oof_preds)\n",
    "    print(f\"Overall OOF AUC: {oof_auc:.5f}\")\n",
    "    \n",
    "    return oof_preds, test_preds, oof_auc\n",
    "\n",
    "print(\"\\n=== Training XGBoost (simple data) ===\")\n",
    "oof_xgb_simple, test_xgb_simple, auc_xgb_simple = train_xgboost(\n",
    "    X_simple, y, X_test_simple, n_splits=N_SPLITS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f0f302",
   "metadata": {},
   "source": [
    "## Part 8: Ensemble (Equal Weights - Avoid Overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8588abf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Comparison ===\n",
      "LGB Simple (no FE):  CV AUC = 0.72853\n",
      "LGB with FE:         CV AUC = 0.72807\n",
      "CatBoost Simple:     CV AUC = 0.72093\n",
      "XGBoost Simple:      CV AUC = 0.72534\n",
      "\n",
      "=== Ensemble Results ===\n",
      "Ensemble (LGB+CAT+XGB, equal):    CV AUC = 0.72593\n",
      "Blend XGB+CAT (60/40):            CV AUC = 0.72415\n",
      "LGB only:                         CV AUC = 0.72853\n",
      "Ensemble (LGB+CAT+XGB, equal):    CV AUC = 0.72593\n",
      "Blend XGB+CAT (60/40):            CV AUC = 0.72415\n",
      "LGB only:                         CV AUC = 0.72853\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Model Comparison ===\")\n",
    "print(f\"LGB Simple (no FE):  CV AUC = {auc_lgb_simple:.5f}\")\n",
    "print(f\"LGB with FE:         CV AUC = {auc_lgb_fe:.5f}\")\n",
    "print(f\"CatBoost Simple:     CV AUC = {auc_cat_simple:.5f}\")\n",
    "print(f\"XGBoost Simple:      CV AUC = {auc_xgb_simple:.5f}\")\n",
    "\n",
    "# Simple equal-weight ensemble (avoid optimizing weights on CV)\n",
    "print(\"\\n=== Ensemble Results ===\")\n",
    "\n",
    "# Ensemble 1: LGB + CatBoost + XGBoost (all simple, equal weights)\n",
    "oof_ensemble = (oof_lgb_simple + oof_cat_simple + oof_xgb_simple) / 3\n",
    "test_ensemble = (test_lgb_simple + test_cat_simple + test_xgb_simple) / 3\n",
    "auc_ensemble = roc_auc_score(y, oof_ensemble)\n",
    "print(f\"Ensemble (LGB+CAT+XGB, equal):    CV AUC = {auc_ensemble:.5f}\")\n",
    "\n",
    "# Ensemble 2: XGB + CatBoost blend (like top-34 solution: 60/40)\n",
    "oof_blend_6040 = 0.6 * oof_xgb_simple + 0.4 * oof_cat_simple\n",
    "test_blend_6040 = 0.6 * test_xgb_simple + 0.4 * test_cat_simple\n",
    "auc_blend_6040 = roc_auc_score(y, oof_blend_6040)\n",
    "print(f\"Blend XGB+CAT (60/40):            CV AUC = {auc_blend_6040:.5f}\")\n",
    "\n",
    "# Ensemble 3: Just LGB (simplest)\n",
    "print(f\"LGB only:                         CV AUC = {auc_lgb_simple:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2234264b",
   "metadata": {},
   "source": [
    "## Part 9: Create Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad84315e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission_v5_lgb_simple.csv (CV AUC: 0.72853)\n",
      "Saved submission_v5_ensemble.csv (CV AUC: 0.72593)\n",
      "Saved submission_v5_ensemble.csv (CV AUC: 0.72593)\n",
      "Saved submission_v5_blend_6040.csv (CV AUC: 0.72415)\n",
      "Saved submission_v5_blend_6040.csv (CV AUC: 0.72415)\n",
      "Saved submission_v5_catboost.csv (CV AUC: 0.72093)\n",
      "Saved submission_v5_catboost.csv (CV AUC: 0.72093)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Save multiple submissions for testing\n",
    "\n",
    "# 1. LGB Simple (no FE) - most conservative\n",
    "sub_lgb = pd.DataFrame({'id': test_ids, 'diagnosed_diabetes': test_lgb_simple})\n",
    "sub_lgb.to_csv('submission_v5_lgb_simple.csv', index=False)\n",
    "print(f\"Saved submission_v5_lgb_simple.csv (CV AUC: {auc_lgb_simple:.5f})\")\n",
    "\n",
    "# 2. Equal weight ensemble\n",
    "sub_ensemble = pd.DataFrame({'id': test_ids, 'diagnosed_diabetes': test_ensemble})\n",
    "sub_ensemble.to_csv('submission_v5_ensemble.csv', index=False)\n",
    "print(f\"Saved submission_v5_ensemble.csv (CV AUC: {auc_ensemble:.5f})\")\n",
    "\n",
    "# 3. XGB+CAT 60/40 blend (top-34 style)\n",
    "sub_blend = pd.DataFrame({'id': test_ids, 'diagnosed_diabetes': test_blend_6040})\n",
    "sub_blend.to_csv('submission_v5_blend_6040.csv', index=False)\n",
    "print(f\"Saved submission_v5_blend_6040.csv (CV AUC: {auc_blend_6040:.5f})\")\n",
    "\n",
    "# 4. CatBoost only\n",
    "sub_cat = pd.DataFrame({'id': test_ids, 'diagnosed_diabetes': test_cat_simple})\n",
    "sub_cat.to_csv('submission_v5_catboost.csv', index=False)\n",
    "print(f\"Saved submission_v5_catboost.csv (CV AUC: {auc_cat_simple:.5f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31d45db",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Key insights from top Kaggle solutions:\n",
    "\n",
    "1. **Simpler models often generalize better** - The top solutions avoided complex feature engineering\n",
    "2. **Native categorical handling** works well (LightGBM/CatBoost)\n",
    "3. **10-fold CV** provides more stable estimates\n",
    "4. **Conservative hyperparameters** (low learning rate, strong regularization)\n",
    "5. **Equal weight ensembles** are safer than optimized weights (which overfit to CV)\n",
    "\n",
    "Submissions to try (in order of expected LB performance):\n",
    "1. `submission_v5_lgb_simple.csv` - Most conservative, likely best LB\n",
    "2. `submission_v5_catboost.csv` - CatBoost handles categories well\n",
    "3. `submission_v5_ensemble.csv` - Equal weight blend\n",
    "4. `submission_v5_blend_6040.csv` - Top-34 style blend"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
